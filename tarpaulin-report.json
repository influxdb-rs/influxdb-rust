{"files":[{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","benches","client.rs"],"content":"use chrono::{DateTime, Utc};\nuse influxdb::{Client, Error, InfluxDbWriteable, ReadQuery};\nuse std::sync::Arc;\nuse std::time::Instant;\nuse tokio::sync::mpsc::unbounded_channel;\nuse tokio::sync::Semaphore;\n\n#[derive(InfluxDbWriteable, Clone)]\nstruct WeatherReading {\n    time: DateTime<Utc>,\n    humidity: i32,\n    #[influxdb(tag)]\n    wind_direction: String,\n}\n\n#[tokio::main]\nasync fn main() {\n    let db_name = \"bench\";\n    let url = \"http://localhost:8086\";\n    let number_of_total_requests = 20000;\n    let concurrent_requests = 1000;\n\n    let client = Client::new(url, db_name);\n    let concurrency_limit = Arc::new(Semaphore::new(concurrent_requests));\n\n    prepare_influxdb(&client, db_name).await;\n    let measurements = generate_measurements(number_of_total_requests);\n    let (tx, mut rx) = unbounded_channel::<Result<String, Error>>();\n\n    let start = Instant::now();\n    for m in measurements {\n        let permit = concurrency_limit.clone().acquire_owned().await;\n        let client_task = client.clone();\n        let tx_task = tx.clone();\n        tokio::spawn(async move {\n            let res = client_task.query(&m.into_query(\"weather\")).await;\n            let _ = tx_task.send(res);\n            drop(permit);\n        });\n    }\n    drop(tx);\n\n    let mut successful_count = 0;\n    let mut error_count = 0;\n    while let Some(res) = rx.recv().await {\n        if res.is_err() {\n            error_count += 1;\n        } else {\n            successful_count += 1;\n        }\n    }\n\n    let end = Instant::now();\n\n    println!(\n        \"Throughput: {:.1} request/s\",\n        1000000.0 * successful_count as f64 / (end - start).as_micros() as f64\n    );\n    println!(\n        \"{} successful requests, {} errors\",\n        successful_count, error_count\n    );\n}\n\nasync fn prepare_influxdb(client: &Client, db_name: &str) {\n    let create_db_stmt = format!(\"CREATE DATABASE {}\", db_name);\n    client\n        .query(&ReadQuery::new(create_db_stmt))\n        .await\n        .expect(\"failed to create database\");\n}\n\nfn generate_measurements(n: u64) -> Vec<WeatherReading> {\n    (0..n)\n        .collect::<Vec<u64>>()\n        .iter_mut()\n        .map(|_| WeatherReading {\n            time: Utc::now(),\n            humidity: 30,\n            wind_direction: String::from(\"north\"),\n        })\n        .collect()\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","client","mod.rs"],"content":"//! Client which can read and write data from InfluxDB.\n//!\n//! # Arguments\n//!\n//!  * `url`: The URL where InfluxDB is running (ex. `http://localhost:8086`).\n//!  * `database`: The Database against which queries and writes will be run.\n//!\n//! # Examples\n//!\n//! ```rust\n//! use influxdb::Client;\n//!\n//! let client = Client::new(\"http://localhost:8086\", \"test\");\n//!\n//! assert_eq!(client.database_name(), \"test\");\n//! ```\n\nuse futures_util::TryFutureExt;\nuse reqwest::{Client as HttpClient, RequestBuilder, Response as HttpResponse};\nuse std::collections::{BTreeMap, HashMap};\nuse std::fmt::{self, Debug, Formatter};\nuse std::sync::Arc;\n\nuse crate::query::QueryType;\nuse crate::{Error, Query};\n\n#[derive(Clone)]\n/// Internal Representation of a Client\npub struct Client {\n    pub(crate) url: Arc<String>,\n    pub(crate) parameters: Arc<HashMap<&'static str, String>>,\n    pub(crate) token: Option<String>,\n    pub(crate) client: HttpClient,\n}\n\nstruct RedactPassword<'a>(&'a HashMap<&'static str, String>);\n\nimpl<'a> Debug for RedactPassword<'a> {\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        let entries = self\n            .0\n            .iter()\n            .map(|(k, v)| match *k {\n                \"p\" => (*k, \"<redacted>\"),\n                _ => (*k, v.as_str()),\n            })\n            .collect::<BTreeMap<&'static str, &str>>();\n        f.debug_map().entries(entries).finish()\n    }\n}\n\nimpl Debug for Client {\n    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"Client\")\n            .field(\"url\", &self.url)\n            .field(\"parameters\", &RedactPassword(&self.parameters))\n            .finish_non_exhaustive()\n    }\n}\n\nimpl Client {\n    /// Instantiates a new [`Client`](crate::Client)\n    ///\n    /// # Arguments\n    ///\n    ///  * `url`: The URL where InfluxDB is running (ex. `http://localhost:8086`).\n    ///  * `database`: The Database against which queries and writes will be run.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use influxdb::Client;\n    ///\n    /// let _client = Client::new(\"http://localhost:8086\", \"test\");\n    /// ```\n    #[must_use = \"Creating a client is pointless unless you use it\"]\n    pub fn new<S1, S2>(url: S1, database: S2) -> Self\n    where\n        S1: Into<String>,\n        S2: Into<String>,\n    {\n        let mut parameters = HashMap::<&str, String>::new();\n        parameters.insert(\"db\", database.into());\n        Client {\n            url: Arc::new(url.into()),\n            parameters: Arc::new(parameters),\n            client: HttpClient::new(),\n            token: None,\n        }\n    }\n\n    /// Add authentication/authorization information to [`Client`](crate::Client)\n    ///\n    /// # Arguments\n    ///\n    /// * username: The Username for InfluxDB.\n    /// * password: The Password for the user.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use influxdb::Client;\n    ///\n    /// let _client = Client::new(\"http://localhost:9086\", \"test\").with_auth(\"admin\", \"password\");\n    /// ```\n    #[must_use = \"Creating a client is pointless unless you use it\"]\n    pub fn with_auth<S1, S2>(mut self, username: S1, password: S2) -> Self\n    where\n        S1: Into<String>,\n        S2: Into<String>,\n    {\n        let mut with_auth = self.parameters.as_ref().clone();\n        with_auth.insert(\"u\", username.into());\n        with_auth.insert(\"p\", password.into());\n        self.parameters = Arc::new(with_auth);\n        self\n    }\n\n    /// Replaces the HTTP Client\n    #[must_use = \"Creating a client is pointless unless you use it\"]\n    pub fn with_http_client(mut self, http_client: HttpClient) -> Self {\n        self.client = http_client;\n        self\n    }\n\n    /// Add authorization token to [`Client`](crate::Client)\n    ///\n    /// This is designed for influxdb 2.0's backward-compatible API which\n    /// requires authorization by default. You can create such token from\n    /// console of influxdb 2.0 .\n    pub fn with_token<S>(mut self, token: S) -> Self\n    where\n        S: Into<String>,\n    {\n        self.token = Some(token.into());\n        self\n    }\n\n    /// Returns the name of the database the client is using\n    pub fn database_name(&self) -> &str {\n        // safe to unwrap: we always set the database name in `Self::new`\n        self.parameters.get(\"db\").unwrap()\n    }\n\n    /// Returns the URL of the InfluxDB installation the client is using\n    pub fn database_url(&self) -> &str {\n        &self.url\n    }\n\n    /// Pings the InfluxDB Server\n    ///\n    /// Returns a tuple of build type and version number\n    pub async fn ping(&self) -> Result<(String, String), Error> {\n        let url = &format!(\"{}/ping\", self.url);\n        let res = self\n            .client\n            .get(url)\n            .send()\n            .await\n            .map_err(|err| Error::ProtocolError {\n                error: err.to_string(),\n            })?;\n\n        const BUILD_HEADER: &str = \"X-Influxdb-Build\";\n        const VERSION_HEADER: &str = \"X-Influxdb-Version\";\n\n        let (build, version) = {\n            let hdrs = res.headers();\n            (\n                hdrs.get(BUILD_HEADER).and_then(|value| value.to_str().ok()),\n                hdrs.get(VERSION_HEADER)\n                    .and_then(|value| value.to_str().ok()),\n            )\n        };\n\n        Ok((build.unwrap().to_owned(), version.unwrap().to_owned()))\n    }\n\n    /// Sends a [`ReadQuery`](crate::ReadQuery) or [`WriteQuery`](crate::WriteQuery) to the InfluxDB Server.\n    ///\n    /// A version capable of parsing the returned string is available under the [serde_integration](crate::integrations::serde_integration)\n    ///\n    /// # Arguments\n    ///\n    ///  * `q`: Query of type [`ReadQuery`](crate::ReadQuery) or [`WriteQuery`](crate::WriteQuery)\n    ///\n    /// # Examples\n    ///\n    /// ```rust,no_run\n    /// use influxdb::{Client, InfluxDbWriteable, Query, Timestamp};\n    /// use std::time::{SystemTime, UNIX_EPOCH};\n    ///\n    /// # #[tokio::main]\n    /// # async fn main() -> Result<(), influxdb::Error> {\n    /// let start = SystemTime::now();\n    /// let since_the_epoch = start\n    ///     .duration_since(UNIX_EPOCH)\n    ///     .expect(\"Time went backwards\")\n    ///     .as_millis();\n    ///\n    /// let client = Client::new(\"http://localhost:8086\", \"test\");\n    /// let query = Timestamp::Milliseconds(since_the_epoch)\n    ///     .try_into_query(\"weather\")\n    ///     .unwrap()\n    ///     .add_field(\"temperature\", 82);\n    /// let results = client.query(query).await?;\n    ///\n    /// # Ok(())\n    /// # }\n    /// ```\n    /// # Errors\n    ///\n    /// If the function can not finish the query,\n    /// a [`Error`] variant will be returned.\n    ///\n    /// [`Error`]: enum.Error.html\n    pub async fn query<Q>(&self, q: Q) -> Result<String, Error>\n    where\n        Q: Query,\n    {\n        let query = q.build().map_err(|err| Error::InvalidQueryError {\n            error: err.to_string(),\n        })?;\n\n        let mut parameters = self.parameters.as_ref().clone();\n        let request_builder = match q.get_type() {\n            QueryType::ReadQuery => {\n                let read_query = query.get();\n                let url = &format!(\"{}/query\", &self.url);\n                parameters.insert(\"q\", read_query.clone());\n\n                if read_query.contains(\"SELECT\") || read_query.contains(\"SHOW\") {\n                    self.client.get(url).query(&parameters)\n                } else {\n                    self.client.post(url).query(&parameters)\n                }\n            }\n            QueryType::WriteQuery(precision) => {\n                let url = &format!(\"{}/write\", &self.url);\n                let mut parameters = self.parameters.as_ref().clone();\n                parameters.insert(\"precision\", precision);\n\n                self.client.post(url).body(query.get()).query(&parameters)\n            }\n        };\n\n        let res = self\n            .auth_if_needed(request_builder)\n            .send()\n            .map_err(|err| Error::ConnectionError {\n                error: err.to_string(),\n            })\n            .await?;\n        check_status(&res)?;\n\n        let body = res.text();\n\n        let s = body.await.map_err(|_| Error::DeserializationError {\n            error: \"response could not be converted to UTF-8\".into(),\n        })?;\n\n        // todo: improve error parsing without serde\n        if s.contains(\"\\\"error\\\"\") || s.contains(\"\\\"Error\\\"\") {\n            return Err(Error::DatabaseError {\n                error: format!(\"influxdb error: {s:?}\"),\n            });\n        }\n\n        Ok(s)\n    }\n\n    fn auth_if_needed(&self, rb: RequestBuilder) -> RequestBuilder {\n        if let Some(ref token) = self.token {\n            rb.header(\"Authorization\", format!(\"Token {token}\"))\n        } else {\n            rb\n        }\n    }\n}\n\npub(crate) fn check_status(res: &HttpResponse) -> Result<(), Error> {\n    let status = res.status();\n    if !status.is_success() {\n        return Err(Error::ApiError(status.into()));\n    }\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::Client;\n    use indoc::indoc;\n\n    #[test]\n    fn test_client_debug_redacted_password() {\n        let client = Client::new(\"https://localhost:8086\", \"db\").with_auth(\"user\", \"pass\");\n        let actual = format!(\"{client:#?}\");\n        let expected = indoc! { r#\"\n            Client {\n                url: \"https://localhost:8086\",\n                parameters: {\n                    \"db\": \"db\",\n                    \"p\": \"<redacted>\",\n                    \"u\": \"user\",\n                },\n                ..\n            }\n        \"# };\n        assert_eq!(actual.trim(), expected.trim());\n    }\n\n    #[test]\n    fn test_fn_database() {\n        let client = Client::new(\"http://localhost:8068\", \"database\");\n        assert_eq!(client.database_name(), \"database\");\n        assert_eq!(client.database_url(), \"http://localhost:8068\");\n    }\n\n    #[test]\n    fn test_with_auth() {\n        let client = Client::new(\"http://localhost:8068\", \"database\");\n        assert_eq!(client.parameters.len(), 1);\n        assert_eq!(client.parameters.get(\"db\").unwrap(), \"database\");\n\n        let with_auth = client.with_auth(\"username\", \"password\");\n        assert_eq!(with_auth.parameters.len(), 3);\n        assert_eq!(with_auth.parameters.get(\"db\").unwrap(), \"database\");\n        assert_eq!(with_auth.parameters.get(\"u\").unwrap(), \"username\");\n        assert_eq!(with_auth.parameters.get(\"p\").unwrap(), \"password\");\n\n        let client = Client::new(\"http://localhost:8068\", \"database\");\n        let with_auth = client.with_token(\"token\");\n        assert_eq!(with_auth.parameters.len(), 1);\n        assert_eq!(with_auth.parameters.get(\"db\").unwrap(), \"database\");\n        assert_eq!(with_auth.token.unwrap(), \"token\");\n    }\n}\n","traces":[{"line":39,"address":[8600359,8600048,8600330],"length":1,"stats":{"Line":1}},{"line":40,"address":[7883135,7883084],"length":1,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[8600111,8600368,8600407],"length":1,"stats":{"Line":3}},{"line":44,"address":[8323176,8323073],"length":1,"stats":{"Line":2}},{"line":45,"address":[7883447],"length":1,"stats":{"Line":1}},{"line":48,"address":[7883158,7883215],"length":1,"stats":{"Line":2}},{"line":53,"address":[8599248],"length":1,"stats":{"Line":1}},{"line":54,"address":[8599266],"length":1,"stats":{"Line":1}},{"line":55,"address":[7882525],"length":1,"stats":{"Line":1}},{"line":56,"address":[8599336],"length":1,"stats":{"Line":1}},{"line":77,"address":[7769981,7770034,7769296,7770064,7770741,7770780],"length":1,"stats":{"Line":12}},{"line":82,"address":[],"length":0,"stats":{"Line":12}},{"line":83,"address":[7770236,7770316,7769556,7769442],"length":1,"stats":{"Line":24}},{"line":85,"address":[7769623,7770383],"length":1,"stats":{"Line":12}},{"line":86,"address":[7886654,7886766],"length":1,"stats":{"Line":24}},{"line":87,"address":[7770574,7769814],"length":1,"stats":{"Line":12}},{"line":107,"address":[7889821,7889184,7889855],"length":1,"stats":{"Line":6}},{"line":112,"address":[7889373,7889266],"length":1,"stats":{"Line":10}},{"line":113,"address":[8143294,8143369],"length":1,"stats":{"Line":12}},{"line":114,"address":[8143442],"length":1,"stats":{"Line":5}},{"line":115,"address":[],"length":0,"stats":{"Line":5}},{"line":116,"address":[],"length":0,"stats":{"Line":5}},{"line":121,"address":[8326592,8326721],"length":1,"stats":{"Line":0}},{"line":122,"address":[8604041,8603972],"length":1,"stats":{"Line":0}},{"line":123,"address":[7886233],"length":1,"stats":{"Line":0}},{"line":131,"address":[7885328,7885590],"length":1,"stats":{"Line":1}},{"line":135,"address":[7885386,7885448],"length":1,"stats":{"Line":2}},{"line":136,"address":[],"length":0,"stats":{"Line":1}},{"line":140,"address":[7885648],"length":1,"stats":{"Line":1}},{"line":142,"address":[8326101],"length":1,"stats":{"Line":1}},{"line":146,"address":[8603408],"length":1,"stats":{"Line":1}},{"line":147,"address":[8326069],"length":1,"stats":{"Line":1}},{"line":153,"address":[8604705,8604096,8604271,8604322,8604112,8604104,8604167,8605990],"length":1,"stats":{"Line":4}},{"line":154,"address":[8326904,8327017],"length":1,"stats":{"Line":2}},{"line":155,"address":[7887863,7887930,7887385,7887550,7887799],"length":1,"stats":{"Line":4}},{"line":157,"address":[8604497],"length":1,"stats":{"Line":1}},{"line":159,"address":[8604929,8604682,8604739,8604301,8604615],"length":1,"stats":{"Line":4}},{"line":160,"address":[8606304,8606176,8606310,8604944,8606251],"length":1,"stats":{"Line":1}},{"line":161,"address":[7889068],"length":1,"stats":{"Line":0}},{"line":167,"address":[8605456],"length":1,"stats":{"Line":1}},{"line":168,"address":[8605260,8605193],"length":1,"stats":{"Line":2}},{"line":170,"address":[8328784,8327924,8328793],"length":1,"stats":{"Line":3}},{"line":171,"address":[7888214],"length":1,"stats":{"Line":1}},{"line":172,"address":[8605383,8606080,8606089],"length":1,"stats":{"Line":3}},{"line":176,"address":[7888390,7888480],"length":1,"stats":{"Line":2}},{"line":217,"address":[8132032,8132212,8131952,8137159],"length":1,"stats":{"Line":15}},{"line":221,"address":[7773704,7781162,7781210,7776143,7780762,7775898,7771083,7780640,7780714,7778593,7771303,7776049,7771209,7781088],"length":1,"stats":{"Line":18}},{"line":222,"address":[7780658,7781106],"length":1,"stats":{"Line":0}},{"line":225,"address":[8132728,8132644,8137667,8137754],"length":1,"stats":{"Line":18}},{"line":226,"address":[7771587,7776442,7776367,7771523],"length":1,"stats":{"Line":18}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[7776577,7771722],"length":1,"stats":{"Line":6}},{"line":229,"address":[7776648,7771876,7771793,7776731],"length":1,"stats":{"Line":12}},{"line":230,"address":[8138277,8138377,8133239,8133337],"length":1,"stats":{"Line":12}},{"line":232,"address":[8133574,8133773,8138443,8138614,8133403,8138825],"length":1,"stats":{"Line":12}},{"line":233,"address":[8138776,8133730,8138564,8133524],"length":1,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":5}},{"line":238,"address":[8137906,8132871],"length":1,"stats":{"Line":3}},{"line":239,"address":[7771672,7772662,7776527,7777545],"length":1,"stats":{"Line":6}},{"line":240,"address":[7772786,7772861,7777744,7777669],"length":1,"stats":{"Line":6}},{"line":241,"address":[],"length":0,"stats":{"Line":6}},{"line":243,"address":[7778539,7777921,7773176,7773345,7777948,7778228,7773650,7773038,7778059,7773065],"length":1,"stats":{"Line":6}},{"line":247,"address":[],"length":0,"stats":{"Line":21}},{"line":248,"address":[7777418,7772535],"length":1,"stats":{"Line":8}},{"line":250,"address":[],"length":0,"stats":{"Line":11}},{"line":251,"address":[7781250,7780962],"length":1,"stats":{"Line":1}},{"line":253,"address":[8135214,8135043,8140370,8135084,8139977,8140301,8132331,8134850,8134901,8135280,8137348,8139920,8140124,8140168],"length":1,"stats":{"Line":42}},{"line":254,"address":[7779049,7779113,7779385,7774211,7774147,7774483],"length":1,"stats":{"Line":12}},{"line":256,"address":[],"length":0,"stats":{"Line":5}},{"line":258,"address":[],"length":0,"stats":{"Line":13}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[7775132,7779936,7775030,7779865,7774959,7780038],"length":1,"stats":{"Line":15}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[7780337,7775365,7775092,7779998],"length":1,"stats":{"Line":0}},{"line":269,"address":[7775177,7780083],"length":1,"stats":{"Line":5}},{"line":272,"address":[7886114,7886085,7885712],"length":1,"stats":{"Line":6}},{"line":273,"address":[7885873,7885747],"length":1,"stats":{"Line":12}},{"line":274,"address":[8603610,8603686,8603910],"length":1,"stats":{"Line":0}},{"line":276,"address":[7885863],"length":1,"stats":{"Line":6}},{"line":281,"address":[7885168],"length":1,"stats":{"Line":3}},{"line":282,"address":[8325934],"length":1,"stats":{"Line":3}},{"line":283,"address":[8325944],"length":1,"stats":{"Line":3}},{"line":284,"address":[8325958],"length":1,"stats":{"Line":1}},{"line":286,"address":[8326038],"length":1,"stats":{"Line":3}}],"covered":74,"coverable":85},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","error.rs"],"content":"//! Errors that might happen in the crate\n\nuse thiserror::Error;\n\n#[derive(Debug, Eq, PartialEq, Error)]\n#[non_exhaustive]\npub enum Error {\n    #[error(\"query is invalid: {error}\")]\n    /// Error happens when a query is invalid\n    InvalidQueryError { error: String },\n\n    #[error(\"Failed to build URL: {error}\")]\n    /// Error happens when a query is invalid\n    UrlConstructionError { error: String },\n\n    #[error(\"http protocol error: {error}\")]\n    /// Error happens when a query is invalid\n    ProtocolError { error: String },\n\n    #[error(\"http protocol error: {error}\")]\n    /// Error happens when Serde cannot deserialize the response\n    DeserializationError { error: String },\n\n    #[error(\"InfluxDB encountered the following error: {error}\")]\n    /// Error which has happened inside InfluxDB\n    DatabaseError { error: String },\n\n    #[error(\"API error with a status code: {0}\")]\n    /// Error happens when API returns non 2xx status code.\n    ApiError(u16),\n\n    #[error(\"connection error: {error}\")]\n    /// Error happens when HTTP request fails\n    ConnectionError { error: String },\n}\n\n#[cfg(feature = \"chrono\")]\n#[derive(Clone, Copy, Debug, Error)]\n#[error(\"The timestamp is too large to fit into an i64.\")]\npub struct TimestampTooLargeError(pub(crate) ());\n\n#[cfg(any(feature = \"chrono\", feature = \"time\"))]\n#[derive(Clone, Copy, Debug, Error)]\npub enum TimeTryFromError<T, I> {\n    TimeError(#[source] T),\n    IntError(#[source] I),\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","integrations","serde_integration","de.rs"],"content":"use super::{Series, TaggedSeries};\nuse serde::de::{\n    value, Deserialize, DeserializeSeed, Deserializer, Error, IntoDeserializer, MapAccess,\n    SeqAccess, Visitor,\n};\nuse serde_derive::Deserialize;\nuse std::fmt;\nuse std::marker::PhantomData;\n\n// Based on https://serde.rs/deserialize-struct.html\nimpl<'de, T> Deserialize<'de> for Series<T>\nwhere\n    T: Deserialize<'de>,\n{\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        // Field name deserializer\n        #[derive(Deserialize)]\n        #[serde(field_identifier, rename_all = \"lowercase\")]\n        enum Field {\n            Name,\n            Columns,\n            Values,\n        }\n\n        struct SeriesVisitor<T> {\n            _inner_type: PhantomData<T>,\n        }\n\n        impl<'de, T> Visitor<'de> for SeriesVisitor<T>\n        where\n            T: Deserialize<'de>,\n        {\n            type Value = Series<T>;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n                formatter.write_str(\"struct Series\")\n            }\n\n            fn visit_map<V>(self, mut map: V) -> Result<Series<T>, V::Error>\n            where\n                V: MapAccess<'de>,\n            {\n                let mut name = None;\n                let mut columns: Option<Vec<String>> = None;\n                let mut values: Option<Vec<T>> = None;\n                while let Some(key) = map.next_key()? {\n                    match key {\n                        Field::Name => {\n                            if name.is_some() {\n                                return Err(Error::duplicate_field(\"name\"));\n                            }\n                            name = Some(map.next_value()?);\n                        }\n                        Field::Columns => {\n                            if columns.is_some() {\n                                return Err(Error::duplicate_field(\"columns\"));\n                            }\n                            columns = Some(map.next_value()?);\n                        }\n                        Field::Values => {\n                            if values.is_some() {\n                                return Err(Error::duplicate_field(\"values\"));\n                            }\n                            // Error out if \"values\" is encountered before \"columns\"\n                            // Hopefully, InfluxDB never does this.\n                            if columns.is_none() {\n                                return Err(Error::custom(\n                                    \"series values encountered before columns\",\n                                ));\n                            }\n                            // Deserialize using a HeaderVec deserializer\n                            // seeded with the headers from the \"columns\" field\n                            values = Some(map.next_value_seed(HeaderVec::<T> {\n                                header: columns.as_ref().unwrap(),\n                                _inner_type: PhantomData,\n                            })?);\n                        }\n                    }\n                }\n                let name = name.ok_or_else(|| Error::missing_field(\"name\"))?;\n                let values = values.unwrap_or_default();\n\n                Ok(Series { name, values })\n            }\n        }\n\n        const FIELDS: &[&str] = &[\"name\", \"values\"];\n        deserializer.deserialize_struct(\n            \"Series\",\n            FIELDS,\n            SeriesVisitor::<T> {\n                _inner_type: PhantomData,\n            },\n        )\n    }\n}\n\n// Based on https://serde.rs/deserialize-struct.html\nimpl<'de, TAG, T> Deserialize<'de> for TaggedSeries<TAG, T>\nwhere\n    TAG: Deserialize<'de>,\n    T: Deserialize<'de>,\n{\n    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        // Field name deserializer\n        #[derive(Deserialize)]\n        #[serde(field_identifier, rename_all = \"lowercase\")]\n        enum Field {\n            Name,\n            Tags,\n            Columns,\n            Values,\n        }\n\n        struct SeriesVisitor<TAG, T> {\n            _tag_type: PhantomData<TAG>,\n            _value_type: PhantomData<T>,\n        }\n\n        impl<'de, TAG, T> Visitor<'de> for SeriesVisitor<TAG, T>\n        where\n            TAG: Deserialize<'de>,\n            T: Deserialize<'de>,\n        {\n            type Value = TaggedSeries<TAG, T>;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n                formatter.write_str(\"struct TaggedSeries\")\n            }\n\n            fn visit_map<V>(self, mut map: V) -> Result<TaggedSeries<TAG, T>, V::Error>\n            where\n                V: MapAccess<'de>,\n            {\n                let mut name = None;\n                let mut tags: Option<TAG> = None;\n                let mut columns: Option<Vec<String>> = None;\n                let mut values: Option<Vec<T>> = None;\n                while let Some(key) = map.next_key()? {\n                    match key {\n                        Field::Name => {\n                            if name.is_some() {\n                                return Err(Error::duplicate_field(\"name\"));\n                            }\n                            name = Some(map.next_value()?);\n                        }\n                        Field::Tags => {\n                            if tags.is_some() {\n                                return Err(Error::duplicate_field(\"tags\"));\n                            }\n                            tags = Some(map.next_value()?);\n                        }\n                        Field::Columns => {\n                            if columns.is_some() {\n                                return Err(Error::duplicate_field(\"columns\"));\n                            }\n                            columns = Some(map.next_value()?);\n                        }\n                        Field::Values => {\n                            if values.is_some() {\n                                return Err(Error::duplicate_field(\"values\"));\n                            }\n                            // Error out if \"values\" is encountered before \"columns\"\n                            // Hopefully, InfluxDB never does this.\n                            if columns.is_none() {\n                                return Err(Error::custom(\n                                    \"series values encountered before columns\",\n                                ));\n                            }\n                            // Deserialize using a HeaderVec deserializer\n                            // seeded with the headers from the \"columns\" field\n                            values = Some(map.next_value_seed(HeaderVec::<T> {\n                                header: columns.as_ref().unwrap(),\n                                _inner_type: PhantomData,\n                            })?);\n                        }\n                    }\n                }\n                let name = name.ok_or_else(|| Error::missing_field(\"name\"))?;\n                let tags = tags.ok_or_else(|| Error::missing_field(\"tags\"))?;\n                let values = values.ok_or_else(|| Error::missing_field(\"values\"))?;\n                Ok(TaggedSeries { name, tags, values })\n            }\n        }\n\n        const FIELDS: &[&str] = &[\"name\", \"tags\", \"values\"];\n        deserializer.deserialize_struct(\n            \"TaggedSeries\",\n            FIELDS,\n            SeriesVisitor::<TAG, T> {\n                _tag_type: PhantomData,\n                _value_type: PhantomData,\n            },\n        )\n    }\n}\n\n// Deserializer that takes a header as a seed\n// and deserializes an array of arrays into a\n// Vec of map-like values using the header as\n// keys and the values as values.\nstruct HeaderVec<'h, T> {\n    header: &'h [String],\n    _inner_type: PhantomData<T>,\n}\n\nimpl<'de, 'h, T> DeserializeSeed<'de> for HeaderVec<'h, T>\nwhere\n    T: Deserialize<'de>,\n{\n    type Value = Vec<T>;\n\n    fn deserialize<D>(self, deserializer: D) -> Result<Self::Value, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        struct HeaderVecVisitor<'h, T> {\n            header: &'h [String],\n            _inner_type: PhantomData<T>,\n        }\n        impl<'de, 'h, T> Visitor<'de> for HeaderVecVisitor<'h, T>\n        where\n            T: Deserialize<'de>,\n        {\n            type Value = Vec<T>;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n                write!(formatter, \"an array of arrays\")\n            }\n\n            fn visit_seq<A>(self, mut seq: A) -> Result<Vec<T>, A::Error>\n            where\n                A: SeqAccess<'de>,\n            {\n                let mut vec = Vec::new();\n\n                while let Some(v) = seq.next_element_seed(RowWithHeader {\n                    header: self.header,\n                    _inner_type: PhantomData,\n                })? {\n                    vec.push(v);\n                }\n\n                Ok(vec)\n            }\n        }\n        deserializer.deserialize_seq(HeaderVecVisitor {\n            header: self.header,\n            _inner_type: PhantomData,\n        })\n    }\n}\n\n// Deserializer that takes a header as a seed\n// and deserializes an array into a map-like\n// value using the header as keys and the values\n// as values.\nstruct RowWithHeader<'h, T> {\n    header: &'h [String],\n    _inner_type: PhantomData<T>,\n}\n\nimpl<'de, 'h, T> DeserializeSeed<'de> for RowWithHeader<'h, T>\nwhere\n    T: Deserialize<'de>,\n{\n    type Value = T;\n\n    fn deserialize<D>(self, deserializer: D) -> Result<Self::Value, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        struct RowWithHeaderVisitor<'h, T> {\n            header: &'h [String],\n            _inner: PhantomData<fn() -> T>,\n        }\n\n        impl<'de, 'h, T> Visitor<'de> for RowWithHeaderVisitor<'h, T>\n        where\n            T: Deserialize<'de>,\n        {\n            type Value = T;\n\n            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n                formatter.write_str(\"array\")\n            }\n\n            fn visit_seq<A>(self, seq: A) -> Result<T, A::Error>\n            where\n                A: SeqAccess<'de>,\n            {\n                // `MapAccessDeserializer` is a wrapper that turns a `MapAccess`\n                // into a `Deserializer`, allowing it to be used as the input to T's\n                // `Deserialize` implementation. T then deserializes itself using\n                // the entries from the map visitor.\n                Deserialize::deserialize(value::MapAccessDeserializer::new(HeaderMapAccess {\n                    header: self.header,\n                    field: 0,\n                    data: seq,\n                }))\n            }\n        }\n\n        deserializer.deserialize_seq(RowWithHeaderVisitor {\n            header: self.header,\n            _inner: PhantomData,\n        })\n    }\n}\n\n// MapAccess implementation that holds a reference to\n// the header for keys and a serde sequence for values.\n// When asked for a key, it returns the next header and\n// advances its header field index. When asked for a value,\n// it tries to deserialize the next element in the serde\n// sequence into the desired type, and returns an error\n// if no element is returned (the sequence is exhausted).\nstruct HeaderMapAccess<'h, A> {\n    header: &'h [String],\n    field: usize,\n    data: A,\n}\n\nimpl<'de, 'h, A> MapAccess<'de> for HeaderMapAccess<'h, A>\nwhere\n    A: SeqAccess<'de>,\n{\n    type Error = <A as SeqAccess<'de>>::Error;\n\n    fn next_key_seed<K: DeserializeSeed<'de>>(\n        &mut self,\n        seed: K,\n    ) -> Result<Option<K::Value>, Self::Error> {\n        let field = match self.header.get(self.field) {\n            None => return Ok(None),\n            Some(field) => field,\n        };\n        self.field += 1;\n        seed.deserialize(field.clone().into_deserializer())\n            .map(Some)\n    }\n\n    fn next_value_seed<K: DeserializeSeed<'de>>(\n        &mut self,\n        seed: K,\n    ) -> Result<K::Value, Self::Error> {\n        match self.data.next_element_seed(seed)? {\n            Some(value) => Ok(value),\n            None => Err(Error::custom(\"next_value_seed called but no value\")),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::Series;\n    use std::borrow::Cow;\n    use std::collections::HashMap;\n\n    const TEST_DATA: &str = r#\"\n    {\n        \"name\": \"series_name\",\n        \"columns\": [\"foo\", \"bar\"],\n        \"values\": [\n            [\"foo_a\", \"bar_a\"],\n            [\"foo_b\", \"bar_b\"]\n        ]\n    }\n    \"#;\n\n    // we can derive all the impls we want here\n    #[derive(Debug, PartialEq, Eq)]\n    struct EqSeries<T> {\n        pub name: String,\n        pub values: Vec<T>,\n    }\n\n    impl<T> From<Series<T>> for EqSeries<T> {\n        fn from(Series { name, values }: Series<T>) -> Self {\n            EqSeries { name, values }\n        }\n    }\n\n    #[test]\n    fn test_deserialize_cow() {\n        // Unfortunately, Cow is not automatically borrowed,\n        // so this is basically equivalent to String, String\n        let result = serde_json::from_str::<Series<HashMap<Cow<str>, Cow<str>>>>(TEST_DATA);\n        assert!(result.is_ok());\n        assert_eq!(\n            EqSeries::from(result.unwrap()),\n            EqSeries {\n                name: \"series_name\".into(),\n                values: vec![\n                    {\n                        let mut h = std::collections::HashMap::new();\n                        h.insert(\"foo\".into(), \"foo_a\".into());\n                        h.insert(\"bar\".into(), \"bar_a\".into());\n                        h\n                    },\n                    {\n                        let mut h = std::collections::HashMap::new();\n                        h.insert(\"foo\".into(), \"foo_b\".into());\n                        h.insert(\"bar\".into(), \"bar_b\".into());\n                        h\n                    },\n                ],\n            },\n        );\n    }\n\n    #[test]\n    fn test_deserialize_borrowed() {\n        use serde_derive::Deserialize;\n\n        // Deserializing a string that cannot be passed through\n        // without escaping will result in an error like this:\n        // `invalid type: string \"\\n\", expected a borrowed string at line 6 column 43`\n        // but if it doesn't need escaping it's fine.\n        #[derive(Deserialize, Debug, PartialEq, Eq)]\n        struct BorrowingStruct<'a> {\n            foo: &'a str,\n            bar: &'a str,\n        }\n\n        let result = serde_json::from_str::<Series<BorrowingStruct>>(TEST_DATA);\n        assert!(result.is_ok(), \"{}\", result.unwrap_err());\n        assert_eq!(\n            EqSeries::from(result.unwrap()),\n            EqSeries {\n                name: \"series_name\".into(),\n                values: vec![\n                    BorrowingStruct {\n                        foo: \"foo_a\",\n                        bar: \"bar_a\",\n                    },\n                    BorrowingStruct {\n                        foo: \"foo_b\",\n                        bar: \"bar_b\",\n                    },\n                ],\n            },\n        );\n    }\n}\n","traces":[{"line":15,"address":[7852080,7852144],"length":1,"stats":{"Line":8}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[7957440,7957376],"length":1,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[7962491,7960014,7962606,7959899,7957504,7960096],"length":1,"stats":{"Line":8}},{"line":46,"address":[7793126],"length":1,"stats":{"Line":8}},{"line":47,"address":[7793165],"length":1,"stats":{"Line":8}},{"line":48,"address":[],"length":0,"stats":{"Line":8}},{"line":49,"address":[7960289,7957633,7957697,7959910,7960225,7962502],"length":1,"stats":{"Line":16}},{"line":50,"address":[7793419],"length":1,"stats":{"Line":8}},{"line":51,"address":[7928881,7921201,7926321,7923761,7918641],"length":1,"stats":{"Line":8}},{"line":52,"address":[7923395,7925955,7918207,7928447,7920767,7920835,7928515,7918275,7925887,7923327],"length":1,"stats":{"Line":16}},{"line":53,"address":[7960606,7958014,7960992,7958400],"length":1,"stats":{"Line":0}},{"line":55,"address":[7926326,7928754,7918294,7923452,7923634,7920854,7918646,7918514,7918332,7926194,7928534,7923766,7923414,7926012,7921206,7928572,7928886,7921074,7925974,7920892],"length":1,"stats":{"Line":16}},{"line":57,"address":[],"length":0,"stats":{"Line":8}},{"line":58,"address":[7793531,7793995],"length":1,"stats":{"Line":16}},{"line":59,"address":[7794021,7794372],"length":1,"stats":{"Line":0}},{"line":61,"address":[7794014,7794357,7794229,7794068],"length":1,"stats":{"Line":16}},{"line":63,"address":[7794905],"length":1,"stats":{"Line":8}},{"line":64,"address":[7924222,7929342,7925937,7920817,7923377,7926782,7921662,7919102,7918257,7928497],"length":1,"stats":{"Line":16}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":16}},{"line":70,"address":[7961947,7958912,7961504,7959355],"length":1,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[7794582,7794670,7794910,7794766],"length":1,"stats":{"Line":8}},{"line":77,"address":[7921780,7929416,7921736,7924340,7919176,7926900,7919220,7924296,7929460,7926856],"length":1,"stats":{"Line":16}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[7794979,7793438,7795664,7795479,7795665],"length":1,"stats":{"Line":16}},{"line":84,"address":[7919849,7924969,7922409,7927529,7930089],"length":1,"stats":{"Line":8}},{"line":86,"address":[],"length":0,"stats":{"Line":8}},{"line":91,"address":[7838680],"length":1,"stats":{"Line":8}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[8045440],"length":1,"stats":{"Line":1}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[7930768],"length":1,"stats":{"Line":0}},{"line":134,"address":[7930793],"length":1,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":1}},{"line":141,"address":[],"length":0,"stats":{"Line":1}},{"line":142,"address":[7930901],"length":1,"stats":{"Line":1}},{"line":143,"address":[],"length":0,"stats":{"Line":1}},{"line":144,"address":[7930945],"length":1,"stats":{"Line":1}},{"line":145,"address":[],"length":0,"stats":{"Line":2}},{"line":146,"address":[7931186],"length":1,"stats":{"Line":1}},{"line":147,"address":[],"length":0,"stats":{"Line":1}},{"line":148,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[7931369,7931589,7931407,7931727],"length":1,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":1}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":2}},{"line":159,"address":[],"length":0,"stats":{"Line":1}},{"line":160,"address":[7931310,7932200],"length":1,"stats":{"Line":2}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[7932434,7932562,7932219,7932273],"length":1,"stats":{"Line":2}},{"line":165,"address":[7933110],"length":1,"stats":{"Line":1}},{"line":166,"address":[],"length":0,"stats":{"Line":2}},{"line":167,"address":[7932628,7933162],"length":1,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":2}},{"line":172,"address":[7932689,7933130],"length":1,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":1}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":2}},{"line":186,"address":[],"length":0,"stats":{"Line":2}},{"line":187,"address":[],"length":0,"stats":{"Line":2}},{"line":188,"address":[7933857],"length":1,"stats":{"Line":1}},{"line":193,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[7953424,7953488],"length":1,"stats":{"Line":9}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[7792320],"length":1,"stats":{"Line":0}},{"line":234,"address":[7792338],"length":1,"stats":{"Line":0}},{"line":237,"address":[7792384,7792443,7792869],"length":1,"stats":{"Line":9}},{"line":241,"address":[7956104,7956600,7956062,7956558],"length":1,"stats":{"Line":18}},{"line":243,"address":[7913713,7914678,7915752,7916182,7915139,7915190,7913654,7915702,7915249,7916131,7916241,7914115,7914166,7913603,7915651,7914225,7914627,7914737],"length":1,"stats":{"Line":18}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[7956949,7956342,7956841,7956450],"length":1,"stats":{"Line":18}},{"line":250,"address":[],"length":0,"stats":{"Line":9}},{"line":253,"address":[],"length":0,"stats":{"Line":9}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[7912912,7912976,7912784,7912720,7912848,7913040],"length":1,"stats":{"Line":9}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[7916873,7916681,7916809,7916745,7916553,7916617],"length":1,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":9}},{"line":302,"address":[7792972],"length":1,"stats":{"Line":9}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[7790918],"length":1,"stats":{"Line":9}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[7789593,7789200],"length":1,"stats":{"Line":9}},{"line":340,"address":[7951873,7951966,7952353,7952434],"length":1,"stats":{"Line":18}},{"line":341,"address":[7952517,7952049],"length":1,"stats":{"Line":9}},{"line":342,"address":[],"length":0,"stats":{"Line":9}},{"line":344,"address":[],"length":0,"stats":{"Line":18}},{"line":345,"address":[],"length":0,"stats":{"Line":18}},{"line":346,"address":[7952696,7952283],"length":1,"stats":{"Line":9}},{"line":349,"address":[7953040,7952736,7953200],"length":1,"stats":{"Line":8}},{"line":353,"address":[7952757,7953052,7953218],"length":1,"stats":{"Line":8}},{"line":354,"address":[],"length":0,"stats":{"Line":8}},{"line":355,"address":[],"length":0,"stats":{"Line":0}}],"covered":70,"coverable":112},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","integrations","serde_integration","mod.rs"],"content":"//! Serde Integration for InfluxDB. Provides deserialization of query returns.\n//!\n//! When querying multiple series in the same query (e.g. with a regex query), it might be desirable to flat map\n//! the resulting series into a single `Vec` like so. The example assumes, that there are weather readings in multiple\n//! series named `weather_<city_name>` (e.g. `weather_berlin`, or `weather_london`). Since we're using a Regex query,\n//! we don't actually know which series will be returned. To assign the city name to the series, we can use the series\n//! `name`, InfluxDB provides alongside query results.\n//!\n//! ```rust,no_run\n//! use influxdb::{Client, Query as _, ReadQuery};\n//! use serde_derive::Deserialize;\n//!\n//! #[derive(Deserialize)]\n//! struct WeatherWithoutCityName {\n//!     temperature: i32,\n//! }\n//!\n//! #[derive(Deserialize)]\n//! struct Weather {\n//!     city_name: String,\n//!     weather: WeatherWithoutCityName,\n//! }\n//!\n//! # #[tokio::main]\n//! # async fn main() -> Result<(), influxdb::Error> {\n//! let client = Client::new(\"http://localhost:8086\", \"test\");\n//! let query = ReadQuery::new(\n//!     \"SELECT temperature FROM /weather_[a-z]*$/ WHERE time > now() - 1m ORDER BY DESC\",\n//! );\n//! let mut db_result = client.json_query(query).await?;\n//! let _result = db_result\n//!     .deserialize_next::<WeatherWithoutCityName>()?\n//!     .series\n//!     .into_iter()\n//!     .map(|mut city_series| {\n//!         let city_name = city_series.name.split(\"_\").collect::<Vec<&str>>().remove(2);\n//!         Weather {\n//!             weather: city_series.values.remove(0),\n//!             city_name: city_name.to_string(),\n//!         }\n//!     })\n//!     .collect::<Vec<Weather>>();\n//! # Ok(())\n//! # }\n//! ```\n\nmod de;\n\nuse serde::de::DeserializeOwned;\nuse serde_derive::Deserialize;\n\nuse crate::client::check_status;\nuse crate::{Client, Error, Query, ReadQuery};\n\n#[derive(Deserialize)]\n#[doc(hidden)]\nstruct _DatabaseError {\n    error: String,\n}\n\n#[derive(Deserialize, Debug)]\n#[doc(hidden)]\npub struct DatabaseQueryResult {\n    pub results: Vec<serde_json::Value>,\n}\n\nimpl DatabaseQueryResult {\n    pub fn deserialize_next<T: 'static>(&mut self) -> Result<Return<T>, Error>\n    where\n        T: DeserializeOwned + Send,\n    {\n        serde_json::from_value::<Return<T>>(self.results.remove(0)).map_err(|err| {\n            Error::DeserializationError {\n                error: format!(\"could not deserialize: {err}\"),\n            }\n        })\n    }\n\n    pub fn deserialize_next_tagged<TAG, T: 'static>(\n        &mut self,\n    ) -> Result<TaggedReturn<TAG, T>, Error>\n    where\n        TAG: DeserializeOwned + Send,\n        T: DeserializeOwned + Send,\n    {\n        serde_json::from_value::<TaggedReturn<TAG, T>>(self.results.remove(0)).map_err(|err| {\n            Error::DeserializationError {\n                error: format!(\"could not deserialize: {err}\"),\n            }\n        })\n    }\n}\n\n#[derive(Deserialize, Debug)]\n#[doc(hidden)]\npub struct Return<T> {\n    #[serde(default = \"Vec::new\")]\n    pub series: Vec<Series<T>>,\n}\n\n#[derive(Debug)]\n/// Represents a returned series from InfluxDB\npub struct Series<T> {\n    pub name: String,\n    pub values: Vec<T>,\n}\n\n#[derive(Deserialize, Debug)]\n#[doc(hidden)]\npub struct TaggedReturn<TAG, T> {\n    #[serde(default = \"Vec::new\")]\n    pub series: Vec<TaggedSeries<TAG, T>>,\n}\n\n#[derive(Debug)]\n/// Represents a returned series from InfluxDB\npub struct TaggedSeries<TAG, T> {\n    pub name: String,\n    pub tags: TAG,\n    pub values: Vec<T>,\n}\n\nimpl Client {\n    pub async fn json_query(&self, q: ReadQuery) -> Result<DatabaseQueryResult, Error> {\n        let query = q.build().map_err(|err| Error::InvalidQueryError {\n            error: err.to_string(),\n        })?;\n\n        let read_query = query.get();\n        let read_query_lower = read_query.to_lowercase();\n\n        if !read_query_lower.contains(\"select\") && !read_query_lower.contains(\"show\") {\n            let error = Error::InvalidQueryError {\n                error: \"Only SELECT and SHOW queries supported with JSON deserialization\".into(),\n            };\n            return Err(error);\n        }\n\n        let url = &format!(\"{}/query\", &self.url);\n        let mut parameters = self.parameters.as_ref().clone();\n        parameters.insert(\"q\", read_query);\n        let mut request_builder = self.client.get(url);\n        if let Some(ref token) = self.token {\n            request_builder = request_builder.header(\"Authorization\", format!(\"Token {token}\"))\n        }\n        let request_builder = request_builder.query(&parameters);\n\n        let res = request_builder\n            .send()\n            .await\n            .map_err(|err| Error::ConnectionError {\n                error: err.to_string(),\n            })?;\n        check_status(&res)?;\n\n        let body = res.bytes();\n\n        let body = body.await.map_err(|err| Error::ProtocolError {\n            error: err.to_string(),\n        })?;\n\n        // Try parsing InfluxDBs { \"error\": \"error message here\" }\n        if let Ok(error) = serde_json::from_slice::<_DatabaseError>(&body) {\n            return Err(Error::DatabaseError { error: error.error });\n        }\n\n        // Json has another structure, let's try actually parsing it to the type we're deserializing\n        serde_json::from_slice::<DatabaseQueryResult>(&body).map_err(|err| {\n            Error::DeserializationError {\n                error: format!(\"serde error: {err}\"),\n            }\n        })\n    }\n}\n","traces":[{"line":68,"address":[7838288],"length":1,"stats":{"Line":6}},{"line":72,"address":[],"length":0,"stats":{"Line":6}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[8043639,8043574,8043895,8043318,8044151,8044342,8044086,8044407,8043383,8043830],"length":1,"stats":{"Line":0}},{"line":79,"address":[8044576],"length":1,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":1}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[8044743,8044678],"length":1,"stats":{"Line":0}},{"line":124,"address":[7852208,7854513,7852429,7856685,7852278,7854319],"length":1,"stats":{"Line":8}},{"line":125,"address":[7852551,7852641,7857362,7854482,7857409,7852422,7857296],"length":1,"stats":{"Line":4}},{"line":126,"address":[8271314],"length":1,"stats":{"Line":0}},{"line":129,"address":[8544206,8544081],"length":1,"stats":{"Line":4}},{"line":130,"address":[8544309,8544213],"length":1,"stats":{"Line":4}},{"line":132,"address":[8544567,8544423,8544332],"length":1,"stats":{"Line":5}},{"line":134,"address":[8267266],"length":1,"stats":{"Line":1}},{"line":136,"address":[7853362],"length":1,"stats":{"Line":1}},{"line":139,"address":[8544509,8544796],"length":1,"stats":{"Line":4}},{"line":140,"address":[7853675,7853592],"length":1,"stats":{"Line":4}},{"line":141,"address":[8545171,8545046],"length":1,"stats":{"Line":4}},{"line":142,"address":[7853846],"length":1,"stats":{"Line":2}},{"line":143,"address":[8268310,8267893],"length":1,"stats":{"Line":2}},{"line":144,"address":[8545424,8545672,8545285,8545659],"length":1,"stats":{"Line":0}},{"line":146,"address":[8545383],"length":1,"stats":{"Line":2}},{"line":148,"address":[7854856,7854441,7854789,7854722,7855351],"length":1,"stats":{"Line":6}},{"line":150,"address":[8545931,8546116,8545778,8543775,8545839],"length":1,"stats":{"Line":8}},{"line":151,"address":[8548784,8546134,8548918,8548912,8548859],"length":1,"stats":{"Line":2}},{"line":152,"address":[8271458],"length":1,"stats":{"Line":0}},{"line":154,"address":[8269102,8269390,8269035],"length":1,"stats":{"Line":5}},{"line":156,"address":[7855170],"length":1,"stats":{"Line":2}},{"line":158,"address":[7852480,7857584,7857714,7855390,7855235,7857655,7855673,7857708,7856835],"length":1,"stats":{"Line":4}},{"line":159,"address":[8271170],"length":1,"stats":{"Line":0}},{"line":163,"address":[7855857,7855947,7855778],"length":1,"stats":{"Line":4}},{"line":164,"address":[8270079],"length":1,"stats":{"Line":0}},{"line":168,"address":[8271823,8270354,8270420,8271817,8271584],"length":1,"stats":{"Line":4}},{"line":169,"address":[8271761],"length":1,"stats":{"Line":0}},{"line":170,"address":[8271606,8271671],"length":1,"stats":{"Line":0}}],"covered":25,"coverable":36},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","lib.rs"],"content":"//! Pull requests are always welcome. See [Contributing](https://github.com/influxdb-rs/influxdb-rust/blob/main/CONTRIBUTING.md) and [Code of Conduct](https://github.com/influxdb-rs/influxdb-rust/blob/main/CODE_OF_CONDUCT.md). For a list of past changes, see [CHANGELOG.md](https://github.com/influxdb-rs/influxdb-rust/blob/main/CHANGELOG.md).\n//!\n//! ## Currently Supported Features\n//!\n//! -   Reading and writing to InfluxDB\n//! -   Optional Serde support for deserialization\n//! -   Running multiple queries in one request (e.g. `SELECT * FROM weather_berlin; SELECT * FROM weather_london`)\n//! -   Writing single or multiple measurements in one request (e.g. `WriteQuery` or `Vec<WriteQuery>` argument)\n//! -   Authenticated and unauthenticated connections\n//! -   `async`/`await` support\n//! -   `#[derive(InfluxDbWriteable)]` derive macro for writing / reading into structs\n//! -   `GROUP BY` support\n//! -   Tokio and async-std support (see example below) or [available backends](https://github.com/influxdb-rs/influxdb-rust/blob/main/influxdb/Cargo.toml)\n//! -   Swappable HTTP backends ([see below](#Choice-of-HTTP-backend))\n//!\n//! # Quickstart\n//!\n//! Add the following to your `Cargo.toml`\n#![doc = cargo_toml!(indent=\"\", \"derive\")]\n//!\n//! For an example with using Serde deserialization, please refer to [serde_integration](crate::integrations::serde_integration)\n//!\n//! ```rust,no_run\n//! use chrono::{DateTime, Utc};\n//! use influxdb::{Client, Error, InfluxDbWriteable, ReadQuery, Timestamp};\n//!\n//! #[tokio::main]\n//! async fn main() -> Result<(), Error> {\n//!     // Connect to db `test` on `http://localhost:8086`\n//!     let client = Client::new(\"http://localhost:8086\", \"test\");\n//!\n//!     #[derive(InfluxDbWriteable)]\n//!     struct WeatherReading {\n//!         time: DateTime<Utc>,\n//!         humidity: i32,\n//!         #[influxdb(tag)]\n//!         wind_direction: String,\n//!     }\n//!\n//!     // Let's write some data into a measurement called `weather`\n//!     let weather_readings = vec![\n//!         WeatherReading {\n//!             time: Timestamp::Hours(1).try_into().unwrap(),\n//!             humidity: 30,\n//!             wind_direction: String::from(\"north\"),\n//!         }\n//!         .try_into_query(\"weather\")\n//!         .unwrap(),\n//!         WeatherReading {\n//!             time: Timestamp::Hours(2).try_into().unwrap(),\n//!             humidity: 40,\n//!             wind_direction: String::from(\"west\"),\n//!         }\n//!         .try_into_query(\"weather\")\n//!         .unwrap(),\n//!     ];\n//!\n//!     client.query(weather_readings).await?;\n//!\n//!     // Read back all records\n//!     let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n//!\n//!     let read_result = client.query(read_query).await?;\n//!     println!(\"{}\", read_result);\n//!     Ok(())\n//! }\n//! ```\n//!\n//! For further examples, check out the integration tests in `tests/integration_tests.rs`\n//! in the repository.\n//!\n//! # Choice of HTTP backend\n//!\n//! To communicate with InfluxDB, you can choose the HTTP backend to be used configuring the appropriate feature. We recommend sticking with the default reqwest-based client, unless you really need async-std compatibility.\n//!\n//! - **[hyper](https://github.com/hyperium/hyper)** (through reqwest, used by default), with [rustls](https://github.com/ctz/rustls)\n#![doc = cargo_toml!(indent=\"\\t\", \"derive\")]\n//! - **[hyper](https://github.com/hyperium/hyper)** (through reqwest), with native TLS (OpenSSL)\n#![doc = cargo_toml!(indent=\"\\t\", default-features = false, \"derive\", \"serde\", \"reqwest-client-native-tls\")]\n//! - **[hyper](https://github.com/hyperium/hyper)** (through reqwest), with vendored native TLS (OpenSSL)\n#![doc = cargo_toml!(indent=\"\\t\", default-features = false, \"derive\", \"serde\", \"reqwest-client-native-tls-vendored\")]\n//!\n//! # License\n//!\n//! [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nmacro_rules! cargo_toml {\n    (indent=$indent:literal, $firstfeat:literal $(, $feature:literal)*) => {\n        cargo_toml_private!($indent, \"\", $firstfeat $(, $feature)*)\n    };\n\n    (indent=$indent:literal, default-features = false, $firstfeat:literal $(, $feature:literal)*) => {\n        cargo_toml_private!($indent, \"default-features = false, \", $firstfeat $(, $feature)*)\n    };\n}\nuse cargo_toml;\n\nmacro_rules! cargo_toml_private {\n    ($indent:literal, $deffeats:literal, $firstfeat:literal $(, $feature:literal)*) => {\n        concat!(\n            $indent,\n            \"```toml\\n\",\n\n            $indent,\n            \"influxdb = { version = \\\"\",\n            env!(\"CARGO_PKG_VERSION\"),\n            \"\\\", \",\n            $deffeats,\n            \"features = [\",\n            \"\\\"\", $firstfeat, \"\\\"\",\n            $(\", \\\"\", $feature, \"\\\"\",)*\n            \"] }\\n\",\n\n            $indent,\n            \"```\"\n        )\n    };\n}\nuse cargo_toml_private;\n\nmod client;\nmod error;\nmod query;\n\npub use client::Client;\npub use error::Error;\npub use query::read_query::ReadQuery;\npub use query::write_query::{Type, WriteQuery};\npub use query::{InfluxDbWriteable, Query, QueryType, Timestamp, ValidQuery};\n\n#[cfg(feature = \"serde\")]\npub mod integrations {\n    #[cfg(feature = \"serde\")]\n    pub mod serde_integration;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","query","consts.rs"],"content":"pub const MINUTES_PER_HOUR: u128 = 60;\npub const SECONDS_PER_MINUTE: u128 = 60;\npub const MILLIS_PER_SECOND: u128 = 1000;\npub const NANOS_PER_MILLI: u128 = 1_000_000;\npub const NANOS_PER_MICRO: u128 = 1000;\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","query","line_proto_term.rs"],"content":"/// InfluxDB Line Protocol escaping helper module.\n/// https://docs.influxdata.com/influxdb/v1.7/write_protocols/line_protocol_tutorial/\nuse crate::Type;\nuse lazy_regex::{lazy_regex, Lazy, Regex};\n\npub static COMMAS_SPACES: Lazy<Regex> = lazy_regex!(\"[, ]\");\npub static COMMAS_SPACES_EQUALS: Lazy<Regex> = lazy_regex!(\"[, =]\");\npub static QUOTES_SLASHES: Lazy<Regex> = lazy_regex!(r#\"[\"\\\\]\"#);\npub static SLASHES: Lazy<Regex> = lazy_regex!(r#\"(\\\\|,| |=|\")\"#);\n\npub enum LineProtoTerm<'a> {\n    Measurement(&'a str), // escape commas, spaces\n    TagKey(&'a str),      // escape commas, equals, spaces\n    TagValue(&'a Type),   // escape commas, equals, spaces\n    FieldKey(&'a str),    // escape commas, equals, spaces\n    FieldValue(&'a Type), // escape quotes, backslashes + quote\n}\n\nimpl LineProtoTerm<'_> {\n    pub fn escape(self) -> String {\n        use LineProtoTerm::*;\n        match self {\n            Measurement(x) => Self::escape_any(x, &COMMAS_SPACES),\n            TagKey(x) | FieldKey(x) => Self::escape_any(x, &COMMAS_SPACES_EQUALS),\n            FieldValue(x) => Self::escape_field_value(x, false),\n            TagValue(x) => Self::escape_tag_value(x),\n        }\n    }\n\n    pub fn escape_v2(self) -> String {\n        use LineProtoTerm::*;\n        match self {\n            Measurement(x) => Self::escape_any(x, &COMMAS_SPACES),\n            TagKey(x) | FieldKey(x) => Self::escape_any(x, &COMMAS_SPACES_EQUALS),\n            FieldValue(x) => Self::escape_field_value(x, true),\n            TagValue(x) => Self::escape_tag_value(x),\n        }\n    }\n\n    fn escape_field_value(v: &Type, use_v2: bool) -> String {\n        use Type::*;\n        match v {\n            Boolean(v) => {\n                if *v {\n                    \"true\"\n                } else {\n                    \"false\"\n                }\n            }\n            .to_string(),\n            Float(v) => v.to_string(),\n            SignedInteger(v) => format!(\"{v}i\"),\n            UnsignedInteger(v) => {\n                if use_v2 {\n                    format!(\"{v}u\")\n                } else {\n                    format!(\"{v}i\")\n                }\n            }\n            Text(v) => format!(r#\"\"{}\"\"#, Self::escape_any(v, &QUOTES_SLASHES)),\n        }\n    }\n\n    fn escape_tag_value(v: &Type) -> String {\n        use Type::*;\n        match v {\n            Boolean(v) => {\n                if *v {\n                    \"true\"\n                } else {\n                    \"false\"\n                }\n            }\n            .into(),\n            Float(v) => v.to_string(),\n            SignedInteger(v) => v.to_string(),\n            UnsignedInteger(v) => v.to_string(),\n            Text(v) => Self::escape_any(v, &SLASHES),\n        }\n    }\n\n    fn escape_any(s: &str, re: &Regex) -> String {\n        re.replace_all(s, r\"\\$0\").to_string()\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use crate::query::line_proto_term::LineProtoTerm::*;\n    use crate::Type;\n\n    #[test]\n    fn test() {\n        assert_eq!(TagValue(&Type::Boolean(true)).escape(), r#\"true\"#);\n        assert_eq!(TagValue(&Type::Float(1.8324f64)).escape(), r#\"1.8324\"#);\n        assert_eq!(TagValue(&Type::SignedInteger(-1i64)).escape(), r#\"-1\"#);\n        assert_eq!(TagValue(&Type::UnsignedInteger(1u64)).escape(), r#\"1\"#);\n\n        assert_eq!(\n            TagValue(&Type::Text(\"this is my special string\".into())).escape(),\n            r\"this\\ is\\ my\\ special\\ string\"\n        );\n        assert_eq!(\n            TagValue(&Type::Text(\"a tag w=i th == tons of escapes\".into())).escape(),\n            r\"a\\ tag\\ w\\=i\\ th\\ \\=\\=\\ tons\\ of\\ escapes\"\n        );\n        assert_eq!(\n            TagValue(&Type::Text(\"no_escapes\".into())).escape(),\n            r#\"no_escapes\"#\n        );\n        assert_eq!(\n            TagValue(&Type::Text(\"some,commas,here\".into())).escape(),\n            r\"some\\,commas\\,here\"\n        );\n\n        assert_eq!(Measurement(r#\"wea\", ther\"#).escape(), r#\"wea\"\\,\\ ther\"#);\n        assert_eq!(TagKey(r\"locat\\ ,=ion\").escape(), r\"locat\\\\ \\,\\=ion\");\n\n        assert_eq!(FieldValue(&Type::Boolean(true)).escape(), r#\"true\"#);\n        assert_eq!(FieldValue(&Type::Boolean(false)).escape(), r#\"false\"#);\n\n        assert_eq!(FieldValue(&Type::Float(0.0)).escape(), r#\"0\"#);\n        assert_eq!(FieldValue(&Type::Float(-0.1)).escape(), r#\"-0.1\"#);\n\n        assert_eq!(FieldValue(&Type::SignedInteger(0)).escape(), r#\"0i\"#);\n        assert_eq!(FieldValue(&Type::SignedInteger(83)).escape(), r#\"83i\"#);\n\n        assert_eq!(FieldValue(&Type::UnsignedInteger(0)).escape(), r#\"0i\"#);\n        assert_eq!(FieldValue(&Type::UnsignedInteger(83)).escape(), r#\"83i\"#);\n\n        assert_eq!(FieldValue(&Type::UnsignedInteger(0)).escape_v2(), r#\"0u\"#);\n        assert_eq!(FieldValue(&Type::UnsignedInteger(83)).escape_v2(), r#\"83u\"#);\n\n        assert_eq!(FieldValue(&Type::Text(\"\".into())).escape(), r#\"\"\"\"#);\n        assert_eq!(FieldValue(&Type::Text(\"0\".into())).escape(), r#\"\"0\"\"#);\n        assert_eq!(FieldValue(&Type::Text(\"\\\"\".into())).escape(), r#\"\"\\\"\"\"#);\n        assert_eq!(\n            FieldValue(&Type::Text(r#\"locat\"\\ ,=ion\"#.into())).escape(),\n            r#\"\"locat\\\"\\\\ ,=ion\"\"#\n        );\n    }\n\n    #[test]\n    fn test_empty_tag_value() {\n        // InfluxDB doesn't support empty tag values. But that's a job\n        // of a calling site to validate an entire write request.\n        assert_eq!(TagValue(&Type::Text(\"\".into())).escape(), r#\"\"#);\n    }\n}\n","traces":[{"line":6,"address":[8549209,8549184],"length":1,"stats":{"Line":6}},{"line":7,"address":[7942121,7942096],"length":1,"stats":{"Line":6}},{"line":8,"address":[8274224,8274249],"length":1,"stats":{"Line":2}},{"line":9,"address":[8274832,8274857],"length":1,"stats":{"Line":4}},{"line":20,"address":[8550960],"length":1,"stats":{"Line":4}},{"line":22,"address":[8273811,8273760,8273635],"length":1,"stats":{"Line":12}},{"line":23,"address":[7941239],"length":1,"stats":{"Line":4}},{"line":24,"address":[8273742,8273793,8273849],"length":1,"stats":{"Line":13}},{"line":25,"address":[8551167],"length":1,"stats":{"Line":3}},{"line":26,"address":[7941339],"length":1,"stats":{"Line":3}},{"line":30,"address":[8551264],"length":1,"stats":{"Line":1}},{"line":32,"address":[8274064,8273939,8274115],"length":1,"stats":{"Line":2}},{"line":33,"address":[8273975],"length":1,"stats":{"Line":2}},{"line":34,"address":[8274156,8274097,8274046],"length":1,"stats":{"Line":2}},{"line":35,"address":[8274127],"length":1,"stats":{"Line":1}},{"line":36,"address":[8551420],"length":1,"stats":{"Line":0}},{"line":40,"address":[8272672,8273600,8273594],"length":1,"stats":{"Line":3}},{"line":42,"address":[7940285],"length":1,"stats":{"Line":3}},{"line":43,"address":[8272781],"length":1,"stats":{"Line":1}},{"line":44,"address":[8272796,8273126,8273154],"length":1,"stats":{"Line":3}},{"line":45,"address":[8273128],"length":1,"stats":{"Line":1}},{"line":47,"address":[8550449],"length":1,"stats":{"Line":1}},{"line":51,"address":[8550165],"length":1,"stats":{"Line":1}},{"line":52,"address":[8550193],"length":1,"stats":{"Line":3}},{"line":53,"address":[8272980],"length":1,"stats":{"Line":1}},{"line":54,"address":[7940558],"length":1,"stats":{"Line":1}},{"line":55,"address":[8273311],"length":1,"stats":{"Line":1}},{"line":57,"address":[8550527],"length":1,"stats":{"Line":1}},{"line":60,"address":[8550783,8550354],"length":1,"stats":{"Line":1}},{"line":64,"address":[7939888],"length":1,"stats":{"Line":3}},{"line":66,"address":[7939912],"length":1,"stats":{"Line":3}},{"line":67,"address":[8272408],"length":1,"stats":{"Line":1}},{"line":68,"address":[7940173,7940201,7939988],"length":1,"stats":{"Line":2}},{"line":69,"address":[7940175],"length":1,"stats":{"Line":1}},{"line":71,"address":[8272588],"length":1,"stats":{"Line":0}},{"line":75,"address":[8272445],"length":1,"stats":{"Line":1}},{"line":76,"address":[8272475],"length":1,"stats":{"Line":1}},{"line":77,"address":[8272505],"length":1,"stats":{"Line":2}},{"line":78,"address":[8272530],"length":1,"stats":{"Line":2}},{"line":82,"address":[8272295,8272301,8272144],"length":1,"stats":{"Line":4}},{"line":83,"address":[8272189],"length":1,"stats":{"Line":4}}],"covered":39,"coverable":41},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","query","mod.rs"],"content":"//! Used to create queries of type [`ReadQuery`](crate::query::read_query::ReadQuery) or\n//! [`WriteQuery`](crate::query::write_query::WriteQuery) which can be executed in InfluxDB\n//!\n//! # Examples\n//!\n//! ```rust\n//! use influxdb::{InfluxDbWriteable, Query as _, ReadQuery, Timestamp};\n//!\n//! let write_query = Timestamp::Nanoseconds(0)\n//!     .try_into_query(\"measurement\")\n//!     .unwrap()\n//!     .add_field(\"field1\", 5)\n//!     .add_tag(\"author\", \"Gero\")\n//!     .build();\n//!\n//! assert!(write_query.is_ok());\n//!\n//! let read_query = ReadQuery::new(\"SELECT * FROM weather\").build();\n//!\n//! assert!(read_query.is_ok());\n//! ```\n\npub mod consts;\nmod line_proto_term;\npub mod read_query;\npub mod write_query;\nuse std::convert::Infallible;\nuse std::fmt;\n\nuse crate::{Error, WriteQuery};\nuse consts::{\n    MILLIS_PER_SECOND, MINUTES_PER_HOUR, NANOS_PER_MICRO, NANOS_PER_MILLI, SECONDS_PER_MINUTE,\n};\n\n#[cfg(feature = \"derive\")]\npub use influxdb_derive::InfluxDbWriteable;\n\n#[derive(PartialEq, Eq, Debug, Copy, Clone)]\npub enum Timestamp {\n    Nanoseconds(u128),\n    Microseconds(u128),\n    Milliseconds(u128),\n    Seconds(u128),\n    Minutes(u128),\n    Hours(u128),\n}\n\nimpl Timestamp {\n    pub fn nanos(&self) -> u128 {\n        match self {\n            Timestamp::Hours(h) => {\n                h * MINUTES_PER_HOUR * SECONDS_PER_MINUTE * MILLIS_PER_SECOND * NANOS_PER_MILLI\n            }\n            Timestamp::Minutes(m) => m * SECONDS_PER_MINUTE * MILLIS_PER_SECOND * NANOS_PER_MILLI,\n            Timestamp::Seconds(s) => s * MILLIS_PER_SECOND * NANOS_PER_MILLI,\n            Timestamp::Milliseconds(millis) => millis * NANOS_PER_MILLI,\n            Timestamp::Microseconds(micros) => micros * NANOS_PER_MICRO,\n            Timestamp::Nanoseconds(nanos) => *nanos,\n        }\n    }\n}\n\nimpl fmt::Display for Timestamp {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        use Timestamp::*;\n        match self {\n            Nanoseconds(ts) | Microseconds(ts) | Milliseconds(ts) | Seconds(ts) | Minutes(ts)\n            | Hours(ts) => write!(f, \"{ts}\"),\n        }\n    }\n}\n\n#[cfg(feature = \"chrono\")]\nimpl TryFrom<Timestamp> for chrono::DateTime<chrono::Utc> {\n    type Error = <i64 as TryFrom<u128>>::Error;\n\n    fn try_from(ts: Timestamp) -> Result<Self, Self::Error> {\n        use chrono::TimeZone as _;\n        Ok(chrono::Utc.timestamp_nanos(ts.nanos().try_into()?))\n    }\n}\n\n#[cfg(feature = \"chrono\")]\nimpl TryFrom<chrono::DateTime<chrono::Utc>> for Timestamp {\n    type Error = crate::error::TimeTryFromError<\n        crate::error::TimestampTooLargeError,\n        <u128 as TryFrom<i64>>::Error,\n    >;\n\n    fn try_from(dt: chrono::DateTime<chrono::Utc>) -> Result<Self, Self::Error> {\n        // unfortunately chrono doesn't give us the nanos as i128, so we have to error\n        // if it doesn't fit and then cast the i64 to u128 anyways\n        let nanos = dt\n            .timestamp_nanos_opt()\n            .ok_or(Self::Error::TimeError(\n                crate::error::TimestampTooLargeError(()),\n            ))?\n            .try_into()\n            .map_err(Self::Error::IntError)?;\n        Ok(Self::Nanoseconds(nanos))\n    }\n}\n\n#[cfg(feature = \"time\")]\nimpl TryFrom<Timestamp> for time::UtcDateTime {\n    type Error =\n        crate::error::TimeTryFromError<time::error::ComponentRange, <i128 as TryFrom<u128>>::Error>;\n\n    fn try_from(value: Timestamp) -> Result<Self, Self::Error> {\n        let nanos = value.nanos().try_into().map_err(Self::Error::IntError)?;\n        time::UtcDateTime::from_unix_timestamp_nanos(nanos).map_err(Self::Error::TimeError)\n    }\n}\n\n#[cfg(feature = \"time\")]\nimpl TryFrom<time::UtcDateTime> for Timestamp {\n    type Error = <u128 as TryFrom<i128>>::Error;\n\n    fn try_from(value: time::UtcDateTime) -> Result<Self, Self::Error> {\n        Ok(Timestamp::Nanoseconds(\n            value.unix_timestamp_nanos().try_into()?,\n        ))\n    }\n}\n\npub trait Query {\n    /// Builds valid InfluxSQL which can be run against the Database.\n    /// In case no fields have been specified, it will return an error,\n    /// as that is invalid InfluxSQL syntax.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use influxdb::{InfluxDbWriteable, Query, Timestamp};\n    ///\n    /// let invalid_query = Timestamp::Nanoseconds(0)\n    ///     .try_into_query(\"measurement\")\n    ///     .unwrap()\n    ///     .build();\n    /// assert!(invalid_query.is_err());\n    ///\n    /// let valid_query = Timestamp::Nanoseconds(0)\n    ///     .try_into_query(\"measurement\")\n    ///     .unwrap()\n    ///     .add_field(\"myfield1\", 11)\n    ///     .build();\n    /// assert!(valid_query.is_ok());\n    /// ```\n    fn build(&self) -> Result<ValidQuery, Error>;\n\n    /// Like [build] but with additional support for unsigned integers in the line protocol.\n    /// Please note, this crate can only interact with InfluxDB 2.0 in compatibility mode\n    /// and does not natively support InfluxDB 2.0.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use influxdb::{InfluxDbWriteable, Query, Timestamp};\n    ///\n    /// let use_v2 = true;\n    ///\n    /// let invalid_query = Timestamp::Nanoseconds(0)\n    ///     .try_into_query(\"measurement\")\n    ///     .unwrap()\n    ///     .build_with_opts(use_v2);\n    /// assert!(invalid_query.is_err());\n    ///\n    /// let valid_query = Timestamp::Nanoseconds(0)\n    ///     .try_into_query(\"measurement\")\n    ///     .unwrap()\n    ///     .add_field(\"myfield1\", 11)\n    ///     .build_with_opts(use_v2);\n    /// assert!(valid_query.is_ok());\n    /// ```\n    fn build_with_opts(&self, use_v2: bool) -> Result<ValidQuery, Error>;\n\n    fn get_type(&self) -> QueryType;\n}\n\nimpl<Q: Query> Query for &Q {\n    fn build(&self) -> Result<ValidQuery, Error> {\n        Q::build_with_opts(self, false)\n    }\n\n    fn build_with_opts(&self, use_v2: bool) -> Result<ValidQuery, Error> {\n        Q::build_with_opts(self, use_v2)\n    }\n\n    fn get_type(&self) -> QueryType {\n        Q::get_type(self)\n    }\n}\n\nimpl<Q: Query> Query for Box<Q> {\n    fn build(&self) -> Result<ValidQuery, Error> {\n        Q::build(self)\n    }\n\n    fn build_with_opts(&self, use_v2: bool) -> Result<ValidQuery, Error> {\n        Q::build_with_opts(self, use_v2)\n    }\n\n    fn get_type(&self) -> QueryType {\n        Q::get_type(self)\n    }\n}\n\npub trait InfluxDbWriteable {\n    type Error;\n\n    fn try_into_query<I: Into<String>>(self, name: I) -> Result<WriteQuery, Self::Error>;\n}\n\nimpl InfluxDbWriteable for Timestamp {\n    type Error = Infallible;\n\n    fn try_into_query<I: Into<String>>(self, name: I) -> Result<WriteQuery, Infallible> {\n        Ok(WriteQuery::new(self, name.into()))\n    }\n}\n\n#[derive(Debug)]\n#[doc(hidden)]\npub struct ValidQuery(String);\nimpl ValidQuery {\n    pub fn get(self) -> String {\n        self.0\n    }\n}\nimpl<T> From<T> for ValidQuery\nwhere\n    T: Into<String>,\n{\n    fn from(string: T) -> Self {\n        Self(string.into())\n    }\n}\nimpl PartialEq<String> for ValidQuery {\n    fn eq(&self, other: &String) -> bool {\n        &self.0 == other\n    }\n}\nimpl PartialEq<&str> for ValidQuery {\n    fn eq(&self, other: &&str) -> bool {\n        &self.0 == other\n    }\n}\n\n/// Internal Enum used to decide if a `POST` or `GET` request should be sent to InfluxDB. See [InfluxDB Docs](https://docs.influxdata.com/influxdb/v1.7/tools/api/#query-http-endpoint).\n#[derive(PartialEq, Eq, Debug)]\npub enum QueryType {\n    ReadQuery,\n    /// write query with precision\n    WriteQuery(String),\n}\n\n#[cfg(test)]\nmod tests {\n    #[cfg(feature = \"chrono\")]\n    use super::consts::{\n        MILLIS_PER_SECOND, MINUTES_PER_HOUR, NANOS_PER_MICRO, NANOS_PER_MILLI, SECONDS_PER_MINUTE,\n    };\n    use crate::query::{Timestamp, ValidQuery};\n\n    #[test]\n    fn test_equality_str() {\n        assert_eq!(ValidQuery::from(\"hello\"), \"hello\");\n    }\n\n    #[test]\n    fn test_equality_string() {\n        assert_eq!(\n            ValidQuery::from(String::from(\"hello\")),\n            String::from(\"hello\")\n        );\n    }\n\n    #[test]\n    fn test_format_for_timestamp_else() {\n        assert!(format!(\"{}\", Timestamp::Nanoseconds(100)) == \"100\");\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_chrono_datetime_from_timestamp_hours() {\n        use chrono::prelude::*;\n        let datetime_from_timestamp: DateTime<Utc> = Timestamp::Hours(2).try_into().unwrap();\n        assert_eq!(\n            Utc.timestamp_nanos(\n                (2 * MINUTES_PER_HOUR * SECONDS_PER_MINUTE * MILLIS_PER_SECOND * NANOS_PER_MILLI)\n                    .try_into()\n                    .unwrap()\n            ),\n            datetime_from_timestamp\n        )\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_chrono_datetime_from_timestamp_minutes() {\n        use chrono::prelude::*;\n        let datetime_from_timestamp: DateTime<Utc> = Timestamp::Minutes(2).try_into().unwrap();\n        assert_eq!(\n            Utc.timestamp_nanos(\n                (2 * SECONDS_PER_MINUTE * MILLIS_PER_SECOND * NANOS_PER_MILLI)\n                    .try_into()\n                    .unwrap()\n            ),\n            datetime_from_timestamp\n        )\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_chrono_datetime_from_timestamp_seconds() {\n        use chrono::prelude::*;\n        let datetime_from_timestamp: DateTime<Utc> = Timestamp::Seconds(2).try_into().unwrap();\n        assert_eq!(\n            Utc.timestamp_nanos(\n                (2 * MILLIS_PER_SECOND * NANOS_PER_MILLI)\n                    .try_into()\n                    .unwrap()\n            ),\n            datetime_from_timestamp\n        )\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_chrono_datetime_from_timestamp_millis() {\n        use chrono::prelude::*;\n        let datetime_from_timestamp: DateTime<Utc> = Timestamp::Milliseconds(2).try_into().unwrap();\n        assert_eq!(\n            Utc.timestamp_nanos((2 * NANOS_PER_MILLI).try_into().unwrap()),\n            datetime_from_timestamp\n        )\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_chrono_datetime_from_timestamp_nanos() {\n        use chrono::prelude::*;\n        let datetime_from_timestamp: DateTime<Utc> = Timestamp::Nanoseconds(1).try_into().unwrap();\n        assert_eq!(Utc.timestamp_nanos(1), datetime_from_timestamp)\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_chrono_datetime_from_timestamp_micros() {\n        use chrono::prelude::*;\n        let datetime_from_timestamp: DateTime<Utc> = Timestamp::Microseconds(2).try_into().unwrap();\n        assert_eq!(\n            Utc.timestamp_nanos((2 * NANOS_PER_MICRO).try_into().unwrap()),\n            datetime_from_timestamp\n        )\n    }\n\n    #[cfg(feature = \"chrono\")]\n    #[test]\n    fn test_timestamp_from_chrono_date() {\n        use chrono::prelude::*;\n        let timestamp_from_datetime: Timestamp = Utc\n            .with_ymd_and_hms(1970, 1, 1, 0, 0, 1)\n            .single()\n            .unwrap()\n            .try_into()\n            .unwrap();\n        assert_eq!(\n            Timestamp::Nanoseconds(MILLIS_PER_SECOND * NANOS_PER_MILLI),\n            timestamp_from_datetime\n        )\n    }\n}\n","traces":[{"line":49,"address":[8673584],"length":1,"stats":{"Line":3}},{"line":50,"address":[7983927],"length":1,"stats":{"Line":3}},{"line":51,"address":[8396738],"length":1,"stats":{"Line":3}},{"line":52,"address":[8397058,8396750,8397233],"length":1,"stats":{"Line":6}},{"line":54,"address":[8674278,8673961],"length":1,"stats":{"Line":2}},{"line":55,"address":[7984148,7984554],"length":1,"stats":{"Line":2}},{"line":56,"address":[8396422],"length":1,"stats":{"Line":1}},{"line":57,"address":[8396360],"length":1,"stats":{"Line":1}},{"line":58,"address":[8396308],"length":1,"stats":{"Line":2}},{"line":64,"address":[8669280],"length":1,"stats":{"Line":6}},{"line":66,"address":[7979886,7979963,7979931,7979995,7979979,7979947],"length":1,"stats":{"Line":11}},{"line":67,"address":[7980002,7980011],"length":1,"stats":{"Line":8}},{"line":77,"address":[8673408],"length":1,"stats":{"Line":3}},{"line":79,"address":[8673441],"length":1,"stats":{"Line":3}},{"line":90,"address":[8375840],"length":1,"stats":{"Line":3}},{"line":93,"address":[8375892,8375946,8376049,8376103],"length":1,"stats":{"Line":4}},{"line":95,"address":[8375879],"length":1,"stats":{"Line":3}},{"line":99,"address":[7953870,7953912],"length":1,"stats":{"Line":2}},{"line":100,"address":[8376158],"length":1,"stats":{"Line":3}},{"line":109,"address":[8372080],"length":1,"stats":{"Line":0}},{"line":110,"address":[8372116],"length":1,"stats":{"Line":0}},{"line":111,"address":[7884963],"length":1,"stats":{"Line":0}},{"line":119,"address":[8374720],"length":1,"stats":{"Line":0}},{"line":120,"address":[7950171],"length":1,"stats":{"Line":0}},{"line":121,"address":[7950048],"length":1,"stats":{"Line":0}},{"line":181,"address":[7819008],"length":1,"stats":{"Line":2}},{"line":182,"address":[],"length":0,"stats":{"Line":2}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":2}},{"line":190,"address":[7819073],"length":1,"stats":{"Line":2}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[7981584,7981760],"length":1,"stats":{"Line":6}},{"line":218,"address":[8070984],"length":1,"stats":{"Line":6}},{"line":226,"address":[7982576],"length":1,"stats":{"Line":7}},{"line":227,"address":[8673379],"length":1,"stats":{"Line":7}},{"line":234,"address":[7981376,7981456],"length":1,"stats":{"Line":2}},{"line":235,"address":[],"length":0,"stats":{"Line":2}},{"line":239,"address":[8674704],"length":1,"stats":{"Line":1}},{"line":240,"address":[8397373],"length":1,"stats":{"Line":1}},{"line":244,"address":[8395984],"length":1,"stats":{"Line":1}},{"line":245,"address":[8395997],"length":1,"stats":{"Line":1}}],"covered":33,"coverable":47},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","query","read_query.rs"],"content":"//! Read Query Builder\n\nuse crate::query::{QueryType, ValidQuery};\nuse crate::{Error, Query};\n\n#[derive(Debug, Clone)]\npub struct ReadQuery {\n    queries: Vec<String>,\n}\n\nimpl ReadQuery {\n    /// Creates a new [`ReadQuery`]\n    #[must_use = \"Creating a query is pointless unless you execute it\"]\n    pub fn new<S>(query: S) -> Self\n    where\n        S: Into<String>,\n    {\n        ReadQuery {\n            queries: vec![query.into()],\n        }\n    }\n\n    /// Adds a query to the [`ReadQuery`]\n    #[must_use = \"Creating a query is pointless unless you execute it\"]\n    pub fn add_query<S>(mut self, query: S) -> Self\n    where\n        S: Into<String>,\n    {\n        self.queries.push(query.into());\n        self\n    }\n}\n\nimpl Query for ReadQuery {\n    fn build(&self) -> Result<ValidQuery, Error> {\n        Ok(ValidQuery(self.queries.join(\";\")))\n    }\n\n    fn build_with_opts(&self, _use_v2: bool) -> Result<ValidQuery, Error> {\n        Ok(ValidQuery(self.queries.join(\";\")))\n    }\n\n    fn get_type(&self) -> QueryType {\n        QueryType::ReadQuery\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::ReadQuery;\n    use crate::query::{Query, QueryType};\n\n    #[test]\n    fn test_read_builder_single_query() {\n        let query = ReadQuery::new(\"SELECT * FROM aachen\").build();\n\n        assert_eq!(query.unwrap(), \"SELECT * FROM aachen\");\n    }\n\n    #[test]\n    fn test_read_builder_multi_query() {\n        let query = ReadQuery::new(\"SELECT * FROM aachen\")\n            .add_query(\"SELECT * FROM cologne\")\n            .build();\n\n        assert_eq!(query.unwrap(), \"SELECT * FROM aachen;SELECT * FROM cologne\");\n    }\n\n    #[test]\n    fn test_correct_query_type() {\n        let query = ReadQuery::new(\"SELECT * FROM aachen\");\n\n        assert_eq!(query.get_type(), QueryType::ReadQuery);\n    }\n}\n","traces":[{"line":14,"address":[7838720,7839120,7839488,7839499,7839081,7839092],"length":1,"stats":{"Line":8}},{"line":19,"address":[],"length":0,"stats":{"Line":14}},{"line":25,"address":[7858336,7858160],"length":1,"stats":{"Line":2}},{"line":29,"address":[],"length":0,"stats":{"Line":4}},{"line":30,"address":[7858309],"length":1,"stats":{"Line":2}},{"line":35,"address":[8265840],"length":1,"stats":{"Line":7}},{"line":36,"address":[8265872],"length":1,"stats":{"Line":7}},{"line":39,"address":[8265680],"length":1,"stats":{"Line":0}},{"line":40,"address":[8265718],"length":1,"stats":{"Line":0}},{"line":43,"address":[8265984],"length":1,"stats":{"Line":7}},{"line":44,"address":[8265992],"length":1,"stats":{"Line":7}}],"covered":9,"coverable":11},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","src","query","write_query.rs"],"content":"//! Write Query Builder returned by Query::write_query\n//!\n//! Can only be instantiated by using Query::write_query\n\nuse crate::query::line_proto_term::LineProtoTerm;\nuse crate::query::{QueryType, ValidQuery};\nuse crate::{Error, Query, Timestamp};\nuse std::fmt::{Display, Formatter};\n\npub trait WriteType {\n    fn add_to(self, tag: String, fields_or_tags: &mut Vec<(String, Type)>);\n}\n\nimpl<T: Into<Type>> WriteType for T {\n    fn add_to(self, tag: String, fields_or_tags: &mut Vec<(String, Type)>) {\n        let val: Type = self.into();\n        fields_or_tags.push((tag, val));\n    }\n}\n\nimpl<T: Into<Type>> WriteType for Option<T> {\n    fn add_to(self, tag: String, fields_or_tags: &mut Vec<(String, Type)>) {\n        if let Some(val) = self {\n            val.add_to(tag, fields_or_tags);\n        }\n    }\n}\n\n/// Internal Representation of a Write query that has not yet been built\n#[derive(Debug, Clone)]\npub struct WriteQuery {\n    fields: Vec<(String, Type)>,\n    tags: Vec<(String, Type)>,\n    measurement: String,\n    timestamp: Timestamp,\n}\n\nimpl WriteQuery {\n    /// Creates a new [`WriteQuery`](crate::query::write_query::WriteQuery)\n    #[must_use = \"Creating a query is pointless unless you execute it\"]\n    pub fn new<S>(timestamp: Timestamp, measurement: S) -> Self\n    where\n        S: Into<String>,\n    {\n        WriteQuery {\n            fields: vec![],\n            tags: vec![],\n            measurement: measurement.into(),\n            timestamp,\n        }\n    }\n\n    /// Adds a field to the [`WriteQuery`](crate::WriteQuery)\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use influxdb::{InfluxDbWriteable, Query, Timestamp};\n    ///\n    /// Timestamp::Nanoseconds(0)\n    ///     .try_into_query(\"measurement\")\n    ///     .unwrap()\n    ///     .add_field(\"field1\", 5)\n    ///     .build();\n    /// ```\n    #[must_use = \"Creating a query is pointless unless you execute it\"]\n    pub fn add_field<S, F>(mut self, field: S, value: F) -> Self\n    where\n        S: Into<String>,\n        F: WriteType,\n    {\n        value.add_to(field.into(), &mut self.fields);\n        self\n    }\n\n    /// Adds a tag to the [`WriteQuery`](crate::WriteQuery)\n    ///\n    /// Please note that a [`WriteQuery`](crate::WriteQuery) requires at least one field. Composing a query with\n    /// only tags will result in a failure building the query.\n    ///\n    /// # Examples\n    ///\n    /// ```rust\n    /// use influxdb::{Query, Timestamp};\n    /// use influxdb::InfluxDbWriteable;\n    ///\n    /// Timestamp::Nanoseconds(0)\n    ///     .try_into_query(\"measurement\").unwrap()\n    ///     .add_tag(\"field1\", 5); // calling `.build()` now would result in a `Err(Error::InvalidQueryError)`\n    /// ```\n    #[must_use = \"Creating a query is pointless unless you execute it\"]\n    pub fn add_tag<S, I>(mut self, tag: S, value: I) -> Self\n    where\n        S: Into<String>,\n        I: WriteType,\n    {\n        value.add_to(tag.into(), &mut self.tags);\n        self\n    }\n\n    pub fn get_precision(&self) -> String {\n        let modifier = match self.timestamp {\n            Timestamp::Nanoseconds(_) => \"ns\",\n            Timestamp::Microseconds(_) => \"u\",\n            Timestamp::Milliseconds(_) => \"ms\",\n            Timestamp::Seconds(_) => \"s\",\n            Timestamp::Minutes(_) => \"m\",\n            Timestamp::Hours(_) => \"h\",\n        };\n        modifier.to_string()\n    }\n}\n\n#[derive(Debug, Clone)]\npub enum Type {\n    Boolean(bool),\n    Float(f64),\n    SignedInteger(i64),\n    UnsignedInteger(u64),\n    Text(String),\n}\n\nimpl Display for Type {\n    fn fmt(&self, f: &mut Formatter) -> std::fmt::Result {\n        use Type::*;\n\n        match self {\n            Boolean(x) => write!(f, \"{x}\"),\n            Float(x) => write!(f, \"{x}\"),\n            SignedInteger(x) => write!(f, \"{x}\"),\n            UnsignedInteger(x) => write!(f, \"{x}\"),\n            Text(text) => write!(f, \"{text}\"),\n        }\n    }\n}\n\nmacro_rules! from_impl {\n        ( $variant:ident => $( $typ:ident ),+ ) => (\n                $(\n                    impl From<$typ> for Type {\n                        fn from(b: $typ) -> Self {\n                            Type::$variant(b.into())\n                        }\n                    }\n                )+\n        )\n}\nfrom_impl! {Boolean => bool}\nfrom_impl! {Float => f32, f64}\nfrom_impl! {SignedInteger => i8, i16, i32, i64}\nfrom_impl! {UnsignedInteger => u8, u16, u32, u64}\nfrom_impl! {Text => String}\nimpl From<&str> for Type {\n    fn from(b: &str) -> Self {\n        Type::Text(b.into())\n    }\n}\n\n#[cfg(feature = \"chrono\")]\nimpl TryFrom<chrono::DateTime<chrono::Utc>> for Type {\n    type Error = crate::error::TimestampTooLargeError;\n\n    fn try_from(dt: chrono::DateTime<chrono::Utc>) -> Result<Self, Self::Error> {\n        let nanos = dt\n            .timestamp_nanos_opt()\n            .ok_or(crate::error::TimestampTooLargeError(()))?;\n        Ok(Self::SignedInteger(nanos))\n    }\n}\n\n#[cfg(feature = \"time\")]\nimpl TryFrom<time::UtcDateTime> for Type {\n    type Error = <i64 as TryFrom<i128>>::Error;\n\n    fn try_from(dt: time::UtcDateTime) -> Result<Self, Self::Error> {\n        let nanos = dt.unix_timestamp_nanos().try_into()?;\n        Ok(Self::SignedInteger(nanos))\n    }\n}\n\nimpl<T> From<&T> for Type\nwhere\n    T: Copy + Into<Type>,\n{\n    fn from(t: &T) -> Self {\n        (*t).into()\n    }\n}\n\nimpl Query for WriteQuery {\n    fn build(&self) -> Result<ValidQuery, Error> {\n        self.build_with_opts(false)\n    }\n\n    fn build_with_opts(&self, use_v2: bool) -> Result<ValidQuery, Error> {\n        if self.fields.is_empty() {\n            return Err(Error::InvalidQueryError {\n                error: \"fields cannot be empty\".to_string(),\n            });\n        }\n\n        let mut tags = self\n            .tags\n            .iter()\n            .map(|(tag, value)| {\n                let escaped_tag_key = if use_v2 {\n                    LineProtoTerm::TagKey(tag).escape_v2()\n                } else {\n                    LineProtoTerm::TagKey(tag).escape()\n                };\n                let escaped_tag_value = if use_v2 {\n                    LineProtoTerm::TagValue(value).escape_v2()\n                } else {\n                    LineProtoTerm::TagValue(value).escape()\n                };\n                format!(\"{escaped_tag_key}={escaped_tag_value}\")\n            })\n            .collect::<Vec<String>>()\n            .join(\",\");\n\n        if !tags.is_empty() {\n            tags.insert(0, ',');\n        }\n        let fields = self\n            .fields\n            .iter()\n            .map(|(field, value)| {\n                let escaped_field_key = if use_v2 {\n                    LineProtoTerm::FieldKey(field).escape_v2()\n                } else {\n                    LineProtoTerm::FieldKey(field).escape()\n                };\n                let escaped_field_value = if use_v2 {\n                    LineProtoTerm::FieldValue(value).escape_v2()\n                } else {\n                    LineProtoTerm::FieldValue(value).escape()\n                };\n                format!(\"{escaped_field_key}={escaped_field_value}\")\n            })\n            .collect::<Vec<String>>()\n            .join(\",\");\n\n        let escaped_measurement = if use_v2 {\n            LineProtoTerm::Measurement(&self.measurement).escape_v2()\n        } else {\n            LineProtoTerm::Measurement(&self.measurement).escape()\n        };\n\n        Ok(ValidQuery(format!(\n            \"{measurement}{tags} {fields} {time}\",\n            measurement = escaped_measurement,\n            tags = tags,\n            fields = fields,\n            time = self.timestamp\n        )))\n    }\n\n    fn get_type(&self) -> QueryType {\n        QueryType::WriteQuery(self.get_precision())\n    }\n}\n\nimpl Query for Vec<WriteQuery> {\n    fn build(&self) -> Result<ValidQuery, Error> {\n        let mut qlines = Vec::new();\n\n        for q in self {\n            let valid_query = q.build()?;\n            qlines.push(valid_query.0);\n        }\n\n        Ok(ValidQuery(qlines.join(\"\\n\")))\n    }\n\n    fn build_with_opts(&self, use_v2: bool) -> Result<ValidQuery, Error> {\n        let mut qlines = Vec::new();\n\n        for q in self {\n            let valid_query = q.build_with_opts(use_v2)?;\n            qlines.push(valid_query.0);\n        }\n\n        Ok(ValidQuery(qlines.join(\"\\n\")))\n    }\n\n    fn get_type(&self) -> QueryType {\n        QueryType::WriteQuery(\n            self.first()\n                .map(|q| q.get_precision())\n                // use \"ms\" as placeholder if query is empty\n                .unwrap_or_else(|| \"ms\".to_owned()),\n        )\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::query::{InfluxDbWriteable, Query, Timestamp};\n\n    #[test]\n    fn test_write_builder_empty_query() {\n        let query = Timestamp::Hours(5)\n            .try_into_query(\"marina_3\".to_string())\n            .unwrap()\n            .build();\n\n        assert!(query.is_err(), \"Query was not empty\");\n    }\n\n    #[test]\n    fn test_write_builder_single_field() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .build();\n\n        assert!(query.is_ok(), \"Query was empty\");\n        assert_eq!(query.unwrap(), \"weather temperature=82i 11\");\n    }\n\n    #[test]\n    fn test_write_builder_multiple_fields() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .add_field(\"wind_strength\", 3.7)\n            .add_field(\"temperature_unsigned\", 82u64)\n            .build();\n\n        assert!(query.is_ok(), \"Query was empty\");\n        assert_eq!(\n            query.unwrap(),\n            \"weather temperature=82i,wind_strength=3.7,temperature_unsigned=82i 11\"\n        );\n    }\n\n    #[test]\n    fn test_write_builder_multiple_fields_with_v2() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .add_field(\"wind_strength\", 3.7)\n            .add_field(\"temperature_unsigned\", 82u64)\n            .build_with_opts(true);\n\n        assert!(query.is_ok(), \"Query was empty\");\n        assert_eq!(\n            query.unwrap(),\n            \"weather temperature=82i,wind_strength=3.7,temperature_unsigned=82u 11\"\n        );\n    }\n\n    #[test]\n    fn test_write_builder_optional_fields() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82u64)\n            .add_tag(\"wind_strength\", <Option<u64>>::None)\n            .build();\n\n        assert!(query.is_ok(), \"Query was empty\");\n        assert_eq!(query.unwrap(), \"weather temperature=82i 11\");\n    }\n\n    #[test]\n    fn test_write_builder_optional_fields_with_v2() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82u64)\n            .add_tag(\"wind_strength\", <Option<u64>>::None)\n            .build_with_opts(true);\n\n        assert!(query.is_ok(), \"Query was empty\");\n        assert_eq!(query.unwrap(), \"weather temperature=82u 11\");\n    }\n\n    #[test]\n    fn test_write_builder_only_tags() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_tag(\"season\", \"summer\")\n            .build();\n\n        assert!(query.is_err(), \"Query missing one or more fields\");\n    }\n\n    #[test]\n    fn test_write_builder_full_query() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .add_tag(\"location\", \"us-midwest\")\n            .add_tag(\"season\", \"summer\")\n            .build();\n\n        assert!(query.is_ok(), \"Query was empty\");\n        assert_eq!(\n            query.unwrap(),\n            r#\"weather,location=us-midwest,season=summer temperature=82i 11\"#\n        );\n    }\n\n    #[test]\n    fn test_correct_query_type() {\n        use crate::query::QueryType;\n\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"weather\".to_string())\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .add_tag(\"location\", \"us-midwest\")\n            .add_tag(\"season\", \"summer\");\n\n        assert_eq!(query.get_type(), QueryType::WriteQuery(\"h\".to_owned()));\n    }\n\n    #[test]\n    fn test_escaping() {\n        let query = Timestamp::Hours(11)\n            .try_into_query(\"wea, ther=\")\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .add_field(\"\\\"temp=era,t ure\\\"\", r#\"too\"\\\\hot\"#)\n            .add_field(\"float\", 82.0)\n            .add_tag(\"location\", \"us-midwest\")\n            .add_tag(\"loc, =\\\"ation\", r#\"us, \"mid=west\"#)\n            .build();\n\n        assert!(query.is_ok(), \"Query was empty\");\n        let query_res = query.unwrap().get();\n        assert_eq!(\n            query_res,\n            r#\"wea\\,\\ ther=,location=us-midwest,loc\\,\\ \\=\"ation=us\\,\\ \\\"mid\\=west temperature=82i,\"temp\\=era\\,t\\ ure\"=\"too\\\"\\\\\\\\hot\",float=82 11\"#\n        );\n    }\n\n    #[test]\n    fn test_batch() {\n        let q0 = Timestamp::Hours(11)\n            .try_into_query(\"weather\")\n            .unwrap()\n            .add_field(\"temperature\", 82)\n            .add_tag(\"location\", \"us-midwest\");\n\n        let q1 = Timestamp::Hours(12)\n            .try_into_query(\"weather\")\n            .unwrap()\n            .add_field(\"temperature\", 65)\n            .add_tag(\"location\", \"us-midwest\");\n\n        let query = vec![q0, q1].build();\n\n        assert_eq!(\n            query.unwrap().get(),\n            r#\"weather,location=us-midwest temperature=82i 11\nweather,location=us-midwest temperature=65i 12\"#\n        );\n    }\n}\n","traces":[{"line":15,"address":[7793104,7793091,7793342,7793062,7792592,7792848,7792834,7792805,7793313,7793360,7793557,7793586],"length":1,"stats":{"Line":9}},{"line":16,"address":[],"length":0,"stats":{"Line":11}},{"line":17,"address":[],"length":0,"stats":{"Line":9}},{"line":22,"address":[7838064],"length":1,"stats":{"Line":4}},{"line":23,"address":[7918061],"length":1,"stats":{"Line":4}},{"line":24,"address":[7838134],"length":1,"stats":{"Line":2}},{"line":41,"address":[7805120,7805515],"length":1,"stats":{"Line":4}},{"line":46,"address":[],"length":0,"stats":{"Line":4}},{"line":47,"address":[8101139],"length":1,"stats":{"Line":5}},{"line":48,"address":[8101188],"length":1,"stats":{"Line":5}},{"line":67,"address":[7840240,7840446],"length":1,"stats":{"Line":8}},{"line":72,"address":[],"length":0,"stats":{"Line":9}},{"line":73,"address":[7840408],"length":1,"stats":{"Line":9}},{"line":92,"address":[7806033,7805777,7805808,7805552],"length":1,"stats":{"Line":6}},{"line":97,"address":[7805885,7805629,7806031,7805775],"length":1,"stats":{"Line":6}},{"line":98,"address":[7840172],"length":1,"stats":{"Line":6}},{"line":101,"address":[7804896],"length":1,"stats":{"Line":4}},{"line":102,"address":[7804915],"length":1,"stats":{"Line":4}},{"line":103,"address":[7804946],"length":1,"stats":{"Line":2}},{"line":104,"address":[7804969],"length":1,"stats":{"Line":0}},{"line":105,"address":[8488640],"length":1,"stats":{"Line":0}},{"line":106,"address":[8211319],"length":1,"stats":{"Line":0}},{"line":107,"address":[8488686],"length":1,"stats":{"Line":0}},{"line":108,"address":[7805061],"length":1,"stats":{"Line":2}},{"line":110,"address":[7805087],"length":1,"stats":{"Line":4}},{"line":124,"address":[8205024],"length":1,"stats":{"Line":0}},{"line":127,"address":[8205056],"length":1,"stats":{"Line":0}},{"line":128,"address":[7794415],"length":1,"stats":{"Line":0}},{"line":129,"address":[8205217],"length":1,"stats":{"Line":0}},{"line":130,"address":[8482683],"length":1,"stats":{"Line":0}},{"line":131,"address":[7794761],"length":1,"stats":{"Line":0}},{"line":132,"address":[7794886],"length":1,"stats":{"Line":0}},{"line":141,"address":[8188144,8209792,8210240,8209872,8210000,8210160,8210944,8210080,8210320,8210400,8209936,8209712],"length":1,"stats":{"Line":7}},{"line":142,"address":[8210261,8209955,8209812,8210192,8188157,8210349,8210432,8209891,8210021,8210969,8209732,8210109],"length":1,"stats":{"Line":8}},{"line":154,"address":[7804800],"length":1,"stats":{"Line":2}},{"line":155,"address":[8488407],"length":1,"stats":{"Line":3}},{"line":163,"address":[7782192],"length":1,"stats":{"Line":0}},{"line":164,"address":[7782242],"length":1,"stats":{"Line":0}},{"line":166,"address":[7782231],"length":1,"stats":{"Line":0}},{"line":167,"address":[8188881],"length":1,"stats":{"Line":0}},{"line":175,"address":[8465920],"length":1,"stats":{"Line":0}},{"line":176,"address":[8465934],"length":1,"stats":{"Line":0}},{"line":177,"address":[7782132],"length":1,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[7803696],"length":1,"stats":{"Line":4}},{"line":192,"address":[8486945],"length":1,"stats":{"Line":4}},{"line":195,"address":[8208384,8206816,8208378],"length":1,"stats":{"Line":4}},{"line":196,"address":[8484221],"length":1,"stats":{"Line":4}},{"line":197,"address":[8484394],"length":1,"stats":{"Line":1}},{"line":198,"address":[7801143],"length":1,"stats":{"Line":1}},{"line":202,"address":[8484243,8484336],"length":1,"stats":{"Line":9}},{"line":205,"address":[7803089,7801086,7802554,7803083,7802512],"length":1,"stats":{"Line":12}},{"line":206,"address":[8485811],"length":1,"stats":{"Line":4}},{"line":207,"address":[7802636],"length":1,"stats":{"Line":0}},{"line":209,"address":[8208479],"length":1,"stats":{"Line":4}},{"line":211,"address":[7802680],"length":1,"stats":{"Line":5}},{"line":212,"address":[8485970,8486098],"length":1,"stats":{"Line":0}},{"line":214,"address":[7802693,7802819],"length":1,"stats":{"Line":7}},{"line":216,"address":[8486058,8486138],"length":1,"stats":{"Line":8}},{"line":221,"address":[8207317],"length":1,"stats":{"Line":4}},{"line":222,"address":[7801525,7801465],"length":1,"stats":{"Line":7}},{"line":224,"address":[8484721,8484843],"length":1,"stats":{"Line":8}},{"line":227,"address":[8486913,8484789,8486336,8486378,8486907],"length":1,"stats":{"Line":10}},{"line":228,"address":[8486403],"length":1,"stats":{"Line":4}},{"line":229,"address":[8486460],"length":1,"stats":{"Line":1}},{"line":231,"address":[7803183],"length":1,"stats":{"Line":4}},{"line":233,"address":[8486504],"length":1,"stats":{"Line":5}},{"line":234,"address":[7803330,7803458],"length":1,"stats":{"Line":2}},{"line":236,"address":[7803285,7803411],"length":1,"stats":{"Line":9}},{"line":238,"address":[7803498,7803418],"length":1,"stats":{"Line":8}},{"line":243,"address":[7801788],"length":1,"stats":{"Line":4}},{"line":244,"address":[7802023,7801835],"length":1,"stats":{"Line":3}},{"line":246,"address":[8485039,8485102],"length":1,"stats":{"Line":8}},{"line":249,"address":[8485356,8485171],"length":1,"stats":{"Line":14}},{"line":258,"address":[7803744],"length":1,"stats":{"Line":4}},{"line":259,"address":[8209651],"length":1,"stats":{"Line":4}},{"line":264,"address":[8325720,8324976,8325750],"length":1,"stats":{"Line":1}},{"line":265,"address":[8325006],"length":1,"stats":{"Line":1}},{"line":267,"address":[8325033,8325105,8325696],"length":1,"stats":{"Line":3}},{"line":268,"address":[8325393,8325187],"length":1,"stats":{"Line":2}},{"line":269,"address":[8325583],"length":1,"stats":{"Line":1}},{"line":272,"address":[8325209],"length":1,"stats":{"Line":1}},{"line":275,"address":[8029638,8029608,8028848],"length":1,"stats":{"Line":0}},{"line":276,"address":[8028893],"length":1,"stats":{"Line":0}},{"line":278,"address":[8028920,8028988,8029581],"length":1,"stats":{"Line":0}},{"line":279,"address":[8324374,8324588],"length":1,"stats":{"Line":0}},{"line":280,"address":[8324781],"length":1,"stats":{"Line":0}},{"line":283,"address":[8029094],"length":1,"stats":{"Line":0}},{"line":286,"address":[8325776],"length":1,"stats":{"Line":0}},{"line":288,"address":[8325808],"length":1,"stats":{"Line":0}},{"line":289,"address":[8211488,8211472],"length":1,"stats":{"Line":0}},{"line":291,"address":[8211436,8211424],"length":1,"stats":{"Line":0}}],"covered":61,"coverable":93},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","tests","derive_integration_tests.rs"],"content":"#[path = \"./utilities.rs\"]\nmod utilities;\n\n#[cfg(feature = \"derive\")]\nuse influxdb::InfluxDbWriteable;\n\nuse chrono::{DateTime, Utc};\nuse influxdb::{Query, ReadQuery, Timestamp};\n\n#[cfg(feature = \"serde\")]\nuse serde_derive::Deserialize;\n\nuse utilities::{assert_result_ok, create_client, create_db, delete_db, run_test};\n\n#[derive(Debug, PartialEq)]\n#[cfg_attr(feature = \"derive\", derive(InfluxDbWriteable))]\nstruct WeatherReading {\n    time: DateTime<Utc>,\n    #[influxdb(ignore)]\n    humidity: i32,\n    pressure: i32,\n    #[influxdb(tag)]\n    wind_strength: Option<u64>,\n}\n\n#[derive(Debug, PartialEq)]\n#[cfg_attr(feature = \"derive\", derive(InfluxDbWriteable))]\nstruct WeatherReadingWithNonstandardTime {\n    #[influxdb(time)]\n    reading_time: DateTime<Utc>,\n    #[influxdb(ignore)]\n    time: DateTime<Utc>,\n    #[influxdb(ignore)]\n    humidity: i32,\n    pressure: i32,\n    #[influxdb(tag)]\n    wind_strength: Option<u64>,\n}\n\n#[derive(Debug)]\n#[cfg_attr(feature = \"serde\", derive(Deserialize))]\nstruct WeatherReadingWithoutIgnored {\n    time: DateTime<Utc>,\n    pressure: i32,\n    wind_strength: Option<u64>,\n}\n\n#[test]\nfn test_build_query() {\n    let weather_reading = WeatherReading {\n        time: Timestamp::Hours(1).try_into().unwrap(),\n        humidity: 30,\n        pressure: 100,\n        wind_strength: Some(5),\n    };\n    let query = weather_reading\n        .try_into_query(\"weather_reading\")\n        .unwrap()\n        .build()\n        .unwrap();\n    assert_eq!(\n        query.get(),\n        \"weather_reading,wind_strength=5 pressure=100i 3600000000000\"\n    );\n}\n\n#[test]\nfn test_build_nonstandard_query() {\n    let weather_reading = WeatherReadingWithNonstandardTime {\n        reading_time: Timestamp::Hours(1).try_into().unwrap(),\n        time: Timestamp::Hours(1).try_into().unwrap(),\n        humidity: 30,\n        pressure: 100,\n        wind_strength: Some(5),\n    };\n    let query = weather_reading\n        .try_into_query(\"weather_reading\")\n        .unwrap()\n        .build()\n        .unwrap();\n    assert_eq!(\n        query.get(),\n        \"weather_reading,wind_strength=5 pressure=100i 3600000000000\"\n    );\n}\n\n#[cfg(feature = \"derive\")]\n/// INTEGRATION TEST\n///\n/// This integration tests that writing data and retrieving the data again is working\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_derive_simple_write() {\n    const TEST_NAME: &str = \"test_derive_simple_write\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n            let client = create_client(TEST_NAME);\n            let weather_reading = WeatherReading {\n                time: Timestamp::Nanoseconds(0).try_into().unwrap(),\n                humidity: 30,\n                wind_strength: Some(5),\n                pressure: 100,\n            };\n            let query = weather_reading.try_into_query(\"weather_reading\").unwrap();\n            let result = client.query(&query).await;\n            assert!(result.is_ok(), \"unable to insert into db\");\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This integration tests that writing data and retrieving the data again is working\n#[cfg(feature = \"derive\")]\n#[cfg(feature = \"serde\")]\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_write_and_read_option() {\n    const TEST_NAME: &str = \"test_write_and_read_option\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n            let client = create_client(TEST_NAME);\n            let weather_reading = WeatherReading {\n                time: Timestamp::Hours(11).try_into().unwrap(),\n                humidity: 30,\n                wind_strength: None,\n                pressure: 100,\n            };\n            let write_result = client\n                .query(\n                    &weather_reading\n                        .try_into_query(\"weather_reading\".to_string())\n                        .unwrap(),\n                )\n                .await;\n            assert_result_ok(&write_result);\n\n            let query = ReadQuery::new(\"SELECT time, pressure, wind_strength FROM weather_reading\");\n            let result = client.json_query(query).await.and_then(|mut db_result| {\n                println!(\"{db_result:?}\");\n                db_result.deserialize_next::<WeatherReadingWithoutIgnored>()\n            });\n            assert_result_ok(&result);\n            let result = result.unwrap();\n            let value = &result.series[0].values[0];\n            assert_eq!(value.time, Timestamp::Hours(11).try_into().unwrap());\n            assert_eq!(value.pressure, 100);\n            assert_eq!(value.wind_strength, None);\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","tests","integration_tests.rs"],"content":"extern crate influxdb;\n\n#[path = \"./utilities.rs\"]\nmod utilities;\n\nuse serde_derive::Deserialize;\nuse utilities::{\n    assert_result_err, assert_result_ok, create_client, create_db, delete_db, run_test,\n};\n\nuse influxdb::{Client, Error, InfluxDbWriteable, ReadQuery, Timestamp};\n\n/// INTEGRATION TEST\n///\n/// This test case tests whether the InfluxDB server can be connected to and gathers info about it - tested with tokio 1.0\n#[tokio::test]\n#[cfg(not(any(tarpaulin_include)))]\nasync fn test_ping_influx_db_tokio() {\n    let client = create_client(\"notusedhere\");\n    let result = client.ping().await;\n    assert_result_ok(&result);\n\n    let (build, version) = result.unwrap();\n    assert!(!build.is_empty(), \"Build should not be empty\");\n    assert!(!version.is_empty(), \"Build should not be empty\");\n\n    println!(\"build: {build} version: {version}\");\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests connection error\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_connection_error() {\n    let test_name = \"test_connection_error\";\n    let client =\n        Client::new(\"http://127.0.0.1:10086\", test_name).with_auth(\"nopriv_user\", \"password\");\n    let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n    let read_result = client.query(read_query).await;\n    assert_result_err(&read_result);\n    match read_result {\n        Err(Error::ConnectionError { .. }) => {}\n        _ => panic!(\n            \"Should cause a ConnectionError: {}\",\n            read_result.unwrap_err()\n        ),\n    }\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the Authentication\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_authed_write_and_read() {\n    const TEST_NAME: &str = \"test_authed_write_and_read\";\n\n    run_test(\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"CREATE DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not setup db\");\n\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(write_query).await;\n            assert_result_ok(&write_result);\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.query(read_query).await;\n            assert_result_ok(&read_result);\n            assert!(\n                !read_result.unwrap().contains(\"error\"),\n                \"Data contained a database error\"\n            );\n        },\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"DROP DATABASE {TEST_NAME}\");\n\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the Authentication\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_wrong_authed_write_and_read() {\n    use http::StatusCode;\n\n    const TEST_NAME: &str = \"test_wrong_authed_write_and_read\";\n\n    run_test(\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"CREATE DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not setup db\");\n\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"wrong_user\", \"password\");\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(write_query).await;\n            assert_result_err(&write_result);\n            match write_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    write_result.unwrap_err()\n                ),\n            }\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.query(read_query).await;\n            assert_result_err(&read_result);\n            match read_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    read_result.unwrap_err()\n                ),\n            }\n\n            let client = Client::new(\"http://127.0.0.1:9086\", TEST_NAME)\n                .with_auth(\"nopriv_user\", \"password\");\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.query(read_query).await;\n            assert_result_err(&read_result);\n            match read_result {\n                Err(Error::ApiError(code)) if code == StatusCode::FORBIDDEN.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHENTICATED): {}\",\n                    read_result.unwrap_err()\n                ),\n            }\n        },\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"DROP DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the Authentication\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_non_authed_write_and_read() {\n    use http::StatusCode;\n\n    const TEST_NAME: &str = \"test_non_authed_write_and_read\";\n\n    run_test(\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"CREATE DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not setup db\");\n            let non_authed_client = Client::new(\"http://127.0.0.1:9086\", TEST_NAME);\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = non_authed_client.query(write_query).await;\n            assert_result_err(&write_result);\n            match write_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    write_result.unwrap_err()\n                ),\n            }\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = non_authed_client.query(read_query).await;\n\n            assert_result_err(&read_result);\n            match read_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    read_result.unwrap_err()\n                ),\n            }\n        },\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"DROP DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This integration tests that writing data and retrieving the data again is working\n#[tokio::test]\n#[cfg(not(tarpaulin_include))]\nasync fn test_write_and_read_field() {\n    const TEST_NAME: &str = \"test_write_field\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n            let client = create_client(TEST_NAME);\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(write_query).await;\n            assert_result_ok(&write_result);\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.query(read_query).await;\n            assert_result_ok(&read_result);\n            assert!(\n                !read_result.unwrap().contains(\"error\"),\n                \"Data contained a database error\"\n            );\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the authentication on json reads\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_json_non_authed_read() {\n    use http::StatusCode;\n\n    const TEST_NAME: &str = \"test_json_non_authed_read\";\n\n    run_test(\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"CREATE DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not setup db\");\n            let non_authed_client = Client::new(\"http://127.0.0.1:9086\", TEST_NAME);\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = non_authed_client.json_query(read_query).await;\n            assert_result_err(&read_result);\n            match read_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    read_result.unwrap_err()\n                ),\n            }\n        },\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"DROP DATABASE {TEST_NAME}\");\n\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not clean up db\");\n        },\n    )\n    .await\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the authentication on json reads\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_json_authed_read() {\n    const TEST_NAME: &str = \"test_json_authed_read\";\n\n    run_test(\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"CREATE DATABASE {TEST_NAME}\");\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not setup db\");\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.json_query(read_query).await;\n            assert_result_ok(&read_result);\n        },\n        || async move {\n            let client =\n                Client::new(\"http://127.0.0.1:9086\", TEST_NAME).with_auth(\"admin\", \"password\");\n            let query = format!(\"DROP DATABASE {TEST_NAME}\");\n\n            client\n                .query(ReadQuery::new(query))\n                .await\n                .expect(\"could not clean up db\");\n        },\n    )\n    .await\n}\n\n/// INTEGRATION TEST\n///\n/// This integration tests that writing data and retrieving the data again is working\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_write_and_read_option() {\n    const TEST_NAME: &str = \"test_write_and_read_option\";\n\n    run_test(\n        || {\n            async move {\n                create_db(TEST_NAME).await.expect(\"could not setup db\");\n\n                let client = create_client(TEST_NAME);\n                // Todo: Convert this to derive based insert for easier comparison of structs\n                let write_query = Timestamp::Hours(11)\n                    .try_into_query(\"weather\")\n                    .unwrap()\n                    .add_field(\"temperature\", 82)\n                    .add_field(\"wind_strength\", <Option<u64>>::None);\n                let write_result = client.query(write_query).await;\n                assert_result_ok(&write_result);\n\n                #[derive(Deserialize, Debug, PartialEq)]\n                struct Weather {\n                    time: String,\n                    // different order to verify field names\n                    // are being used instead of just order\n                    wind_strength: Option<u64>,\n                    temperature: i32,\n                }\n\n                let query = ReadQuery::new(\"SELECT time, temperature, wind_strength FROM weather\");\n                let result = client\n                    .json_query(query)\n                    .await\n                    .and_then(|mut db_result| db_result.deserialize_next::<Weather>());\n                assert_result_ok(&result);\n\n                assert_eq!(\n                    result.unwrap().series[0].values[0],\n                    Weather {\n                        time: \"1970-01-01T11:00:00Z\".to_string(),\n                        temperature: 82,\n                        wind_strength: None,\n                    }\n                );\n            }\n        },\n        || async move {\n            delete_db(\"test_write_and_read_option\")\n                .await\n                .expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests whether JSON can be decoded from a InfluxDB response and whether that JSON\n/// is equal to the data which was written to the database\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_json_query() {\n    const TEST_NAME: &str = \"test_json_query\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n\n            let client = create_client(TEST_NAME);\n\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(write_query).await;\n            assert_result_ok(&write_result);\n\n            #[derive(Deserialize, Debug, PartialEq)]\n            struct Weather {\n                time: String,\n                temperature: i32,\n            }\n\n            let query = ReadQuery::new(\"SELECT * FROM weather\");\n            let result = client\n                .json_query(query)\n                .await\n                .and_then(|mut db_result| db_result.deserialize_next::<Weather>());\n            assert_result_ok(&result);\n\n            assert_eq!(\n                result.unwrap().series[0].values[0],\n                Weather {\n                    time: \"1970-01-01T11:00:00Z\".to_string(),\n                    temperature: 82\n                }\n            );\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests whether the response to a GROUP BY can be parsed by\n/// deserialize_next_tagged into a tags struct\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_json_query_tagged() {\n    const TEST_NAME: &str = \"test_json_query_tagged\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n\n            let client = create_client(TEST_NAME);\n\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_tag(\"location\", \"London\")\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(write_query).await;\n            assert_result_ok(&write_result);\n\n            #[derive(Deserialize, Debug, PartialEq)]\n            struct WeatherMeta {\n                location: String,\n            }\n\n            #[derive(Deserialize, Debug, PartialEq)]\n            struct Weather {\n                time: String,\n                temperature: i32,\n            }\n\n            let query = ReadQuery::new(\"SELECT * FROM weather GROUP BY location\");\n            let result = client.json_query(query).await.and_then(|mut db_result| {\n                db_result.deserialize_next_tagged::<WeatherMeta, Weather>()\n            });\n            assert_result_ok(&result);\n            let result = result.unwrap();\n\n            assert_eq!(\n                result.series[0].tags,\n                WeatherMeta {\n                    location: \"London\".to_string(),\n                }\n            );\n            assert_eq!(\n                result.series[0].values[0],\n                Weather {\n                    time: \"1970-01-01T11:00:00Z\".to_string(),\n                    temperature: 82\n                }\n            );\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests whether JSON can be decoded from a InfluxDB response and whether that JSON\n/// is equal to the data which was written to the database\n/// (tested with tokio)\n#[tokio::test]\n#[cfg(all(feature = \"serde\", not(any(tarpaulin_include))))]\nasync fn test_json_query_vec() {\n    const TEST_NAME: &str = \"test_json_query_vec\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n\n            let client = create_client(TEST_NAME);\n            let write_query1 = Timestamp::Hours(11)\n                .try_into_query(\"temperature_vec\")\n                .unwrap()\n                .add_field(\"temperature\", 16);\n            let write_query2 = Timestamp::Hours(12)\n                .try_into_query(\"temperature_vec\")\n                .unwrap()\n                .add_field(\"temperature\", 17);\n            let write_query3 = Timestamp::Hours(13)\n                .try_into_query(\"temperature_vec\")\n                .unwrap()\n                .add_field(\"temperature\", 18);\n\n            let _write_result = client.query(write_query1).await;\n            let _write_result2 = client.query(write_query2).await;\n            let _write_result2 = client.query(write_query3).await;\n\n            #[derive(Deserialize, Debug, PartialEq)]\n            struct Weather {\n                time: String,\n                temperature: i32,\n            }\n\n            let query = ReadQuery::new(\"SELECT * FROM temperature_vec\");\n            let result = client\n                .json_query(query)\n                .await\n                .and_then(|mut db_result| db_result.deserialize_next::<Weather>());\n            assert_result_ok(&result);\n            assert_eq!(result.unwrap().series[0].values.len(), 3);\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This integration test tests whether using the wrong query method fails building the query\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_serde_multi_query() {\n    const TEST_NAME: &str = \"test_serde_multi_query\";\n\n    run_test(\n        || async move {\n            create_db(TEST_NAME).await.expect(\"could not setup db\");\n\n            #[derive(Deserialize, Debug, PartialEq)]\n            struct Temperature {\n                time: String,\n                temperature: i32,\n            }\n\n            #[derive(Deserialize, Debug, PartialEq)]\n            struct Humidity {\n                time: String,\n                humidity: i32,\n            }\n\n            let client = create_client(TEST_NAME);\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"temperature\")\n                .unwrap()\n                .add_field(\"temperature\", 16);\n            let write_query2 = Timestamp::Hours(11)\n                .try_into_query(\"humidity\")\n                .unwrap()\n                .add_field(\"humidity\", 69);\n\n            let write_result = client.query(write_query).await;\n            let write_result2 = client.query(write_query2).await;\n            assert_result_ok(&write_result);\n            assert_result_ok(&write_result2);\n\n            let result = client\n                .json_query(\n                    ReadQuery::new(\"SELECT * FROM temperature\").add_query(\"SELECT * FROM humidity\"),\n                )\n                .await\n                .and_then(|mut db_result| {\n                    let temp = db_result.deserialize_next::<Temperature>()?;\n                    let humidity = db_result.deserialize_next::<Humidity>()?;\n\n                    Ok((temp, humidity))\n                });\n            assert_result_ok(&result);\n\n            let (temp, humidity) = result.unwrap();\n            assert_eq!(\n                temp.series[0].values[0],\n                Temperature {\n                    time: \"1970-01-01T11:00:00Z\".to_string(),\n                    temperature: 16\n                },\n            );\n            assert_eq!(\n                humidity.series[0].values[0],\n                Humidity {\n                    time: \"1970-01-01T11:00:00Z\".to_string(),\n                    humidity: 69\n                }\n            );\n        },\n        || async move {\n            delete_db(TEST_NAME).await.expect(\"could not clean up db\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This integration test tests whether using the wrong query method fails building the query\n#[tokio::test]\n#[cfg(feature = \"serde\")]\n#[cfg(not(tarpaulin_include))]\nasync fn test_wrong_query_errors() {\n    let client = create_client(\"test_name\");\n    let result = client\n        .json_query(ReadQuery::new(\"CREATE DATABASE this_should_fail\"))\n        .await;\n    assert!(\n        result.is_err(),\n        \"Should only build SELECT and SHOW queries.\"\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","tests","integration_tests_v2.rs"],"content":"extern crate influxdb;\n\n#[path = \"./utilities.rs\"]\nmod utilities;\nuse utilities::{assert_result_err, assert_result_ok, run_test};\n\nuse influxdb::{Client, Error, InfluxDbWriteable, ReadQuery, Timestamp};\n\n/// INTEGRATION TEST\n///\n/// This test case tests the Authentication\n#[tokio::test]\n#[cfg(not(tarpaulin))]\nasync fn test_authed_write_and_read() {\n    run_test(\n        || async move {\n            let client = Client::new(\"http://127.0.0.1:2086\", \"mydb\").with_token(\"admintoken\");\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(&write_query).await;\n            assert_result_ok(&write_result);\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.query(read_query).await;\n            assert_result_ok(&read_result);\n            assert!(\n                !read_result.unwrap().contains(\"error\"),\n                \"Data contained a database error\"\n            );\n        },\n        || async move {\n            let client = Client::new(\"http://127.0.0.1:2086\", \"mydb\").with_token(\"admintoken\");\n            let read_query = ReadQuery::new(\"DROP MEASUREMENT \\\"weather\\\"\");\n            let read_result = client.query(read_query).await;\n            assert_result_ok(&read_result);\n            assert!(!read_result.unwrap().contains(\"error\"), \"Teardown failed\");\n        },\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the Authentication\n#[tokio::test]\n#[cfg(not(tarpaulin))]\nasync fn test_wrong_authed_write_and_read() {\n    use http::StatusCode;\n\n    run_test(\n        || async move {\n            let client = Client::new(\"http://127.0.0.1:2086\", \"mydb\").with_token(\"falsetoken\");\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = client.query(&write_query).await;\n            assert_result_err(&write_result);\n            match write_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    write_result.unwrap_err()\n                ),\n            }\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = client.query(&read_query).await;\n            assert_result_err(&read_result);\n            match read_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    read_result.unwrap_err()\n                ),\n            }\n        },\n        || async move {},\n    )\n    .await;\n}\n\n/// INTEGRATION TEST\n///\n/// This test case tests the Authentication\n#[tokio::test]\n#[cfg(not(tarpaulin))]\nasync fn test_non_authed_write_and_read() {\n    use http::StatusCode;\n\n    run_test(\n        || async move {\n            let non_authed_client = Client::new(\"http://127.0.0.1:2086\", \"mydb\");\n            let write_query = Timestamp::Hours(11)\n                .try_into_query(\"weather\")\n                .unwrap()\n                .add_field(\"temperature\", 82);\n            let write_result = non_authed_client.query(&write_query).await;\n            assert_result_err(&write_result);\n            match write_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    write_result.unwrap_err()\n                ),\n            }\n\n            let read_query = ReadQuery::new(\"SELECT * FROM weather\");\n            let read_result = non_authed_client.query(&read_query).await;\n            assert_result_err(&read_result);\n            match read_result {\n                Err(Error::ApiError(code)) if code == StatusCode::UNAUTHORIZED.as_u16() => {}\n                _ => panic!(\n                    \"Should be an ApiError(UNAUTHORIZED): {}\",\n                    read_result.unwrap_err()\n                ),\n            }\n        },\n        || async move {},\n    )\n    .await;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb","tests","utilities.rs"],"content":"use futures_util::FutureExt;\nuse influxdb::{Client, Error, ReadQuery};\nuse std::future::Future;\nuse std::panic::{AssertUnwindSafe, UnwindSafe};\n\n#[allow(dead_code)]\n#[cfg(not(tarpaulin_include))]\npub fn assert_result_err<A: std::fmt::Debug, B: std::fmt::Debug>(result: &Result<A, B>) {\n    result.as_ref().expect_err(\"assert_result_err failed\");\n}\n\n#[cfg(not(tarpaulin_include))]\npub fn assert_result_ok<A: std::fmt::Debug, B: std::fmt::Debug>(result: &Result<A, B>) {\n    result.as_ref().expect(\"assert_result_ok failed\");\n}\n\n#[allow(dead_code)]\n#[cfg(not(tarpaulin_include))]\npub fn create_client<T>(db_name: T) -> Client\nwhere\n    T: Into<String>,\n{\n    Client::new(\"http://127.0.0.1:8086\", db_name)\n}\n\n#[allow(dead_code)]\n#[cfg(not(tarpaulin_include))]\npub async fn create_db<T>(name: T) -> Result<String, Error>\nwhere\n    T: Into<String>,\n{\n    let test_name = name.into();\n    let query = format!(\"CREATE DATABASE {test_name}\");\n    create_client(test_name).query(ReadQuery::new(query)).await\n}\n\n#[allow(dead_code)]\n#[cfg(not(tarpaulin_include))]\npub async fn delete_db<T>(name: T) -> Result<String, Error>\nwhere\n    T: Into<String>,\n{\n    let test_name = name.into();\n    let query = format!(\"DROP DATABASE {test_name}\");\n    create_client(test_name).query(ReadQuery::new(query)).await\n}\n\n#[cfg(not(tarpaulin_include))]\npub async fn run_test<F, T, Fut1, Fut2>(test_fn: F, teardown: T)\nwhere\n    F: FnOnce() -> Fut1 + UnwindSafe,\n    T: FnOnce() -> Fut2,\n    Fut1: Future,\n    Fut2: Future,\n{\n    let test_result = AssertUnwindSafe(test_fn()).catch_unwind().await;\n    AssertUnwindSafe(teardown())\n        .catch_unwind()\n        .await\n        .expect(\"failed teardown\");\n    test_result.expect(\"failed test\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb_derive","src","lib.rs"],"content":"use proc_macro::TokenStream;\n\nmod writeable;\nuse syn::parse_macro_input;\nuse writeable::expand_writeable;\n\n#[proc_macro_derive(InfluxDbWriteable, attributes(influxdb))]\npub fn derive_writeable(input: TokenStream) -> TokenStream {\n    expand_writeable(parse_macro_input!(input))\n        .unwrap_or_else(syn::Error::into_compile_error)\n        .into()\n}\n","traces":[{"line":8,"address":[1009187,1008896,1009193],"length":1,"stats":{"Line":0}},{"line":9,"address":[1008912,1009099],"length":1,"stats":{"Line":0}},{"line":10,"address":[1009044],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":3},{"path":["/","home","runner","work","influxdb-rust","influxdb-rust","influxdb_derive","src","writeable.rs"],"content":"use proc_macro2::{Span, TokenStream};\nuse quote::{format_ident, quote};\nuse syn::parse::{Parse, ParseStream};\nuse syn::punctuated::Punctuated;\nuse syn::{\n    AngleBracketedGenericArguments, Data, DeriveInput, Field, Fields, GenericArgument, Ident,\n    Lifetime, Meta, PathArguments, PredicateType, Token, Type, TypeParamBound, WhereClause,\n    WherePredicate,\n};\nuse syn_path::type_path;\n\n#[derive(Debug)]\nstruct WriteableField {\n    ident: Ident,\n    ty: Type,\n    is_time: bool,\n    is_tag: bool,\n    is_ignore: bool,\n}\n\nmod kw {\n    use syn::custom_keyword;\n\n    custom_keyword!(time);\n    custom_keyword!(tag);\n    custom_keyword!(ignore);\n}\n\n#[allow(dead_code)] // TODO do we need to store the keywords?\nenum FieldAttr {\n    Time(kw::time),\n    Tag(kw::tag),\n    Ignore(kw::ignore),\n}\n\nimpl Parse for FieldAttr {\n    fn parse(input: ParseStream<'_>) -> syn::Result<Self> {\n        let lookahead = input.lookahead1();\n        if lookahead.peek(kw::time) {\n            Ok(Self::Time(input.parse()?))\n        } else if lookahead.peek(kw::tag) {\n            Ok(Self::Tag(input.parse()?))\n        } else if lookahead.peek(kw::ignore) {\n            Ok(Self::Ignore(input.parse()?))\n        } else {\n            Err(lookahead.error())\n        }\n    }\n}\n\nstruct FieldAttrs(Punctuated<FieldAttr, Token![,]>);\n\nimpl Parse for FieldAttrs {\n    fn parse(input: ParseStream<'_>) -> syn::Result<Self> {\n        Ok(Self(Punctuated::parse_terminated(input)?))\n    }\n}\n\nimpl TryFrom<Field> for WriteableField {\n    type Error = syn::Error;\n\n    fn try_from(field: Field) -> syn::Result<WriteableField> {\n        let ident = field.ident.expect(\"fields without ident are not supported\");\n        let ty = field.ty;\n        let mut has_time_attr = false;\n        let mut is_tag = false;\n        let mut is_ignore = false;\n\n        for attr in field.attrs {\n            match attr.meta {\n                Meta::List(list) if list.path.is_ident(\"influxdb\") => {\n                    for attr in syn::parse2::<FieldAttrs>(list.tokens)?.0 {\n                        match attr {\n                            FieldAttr::Time(_) => has_time_attr = true,\n                            FieldAttr::Tag(_) => is_tag = true,\n                            FieldAttr::Ignore(_) => is_ignore = true,\n                        }\n                    }\n                }\n                _ => {}\n            }\n        }\n\n        if [has_time_attr, is_tag, is_ignore]\n            .iter()\n            .filter(|&&b| b)\n            .count()\n            > 1\n        {\n            panic!(\"only one of time, tag, or ignore can be used\");\n        }\n\n        // A field is considered a time field if:\n        // 1. It has the #[influxdb(time)] attribute, OR\n        // 2. It's named \"time\" and doesn't have #[influxdb(ignore)]\n        let is_time = has_time_attr || (ident == \"time\" && !is_ignore);\n\n        Ok(WriteableField {\n            ident,\n            ty,\n            is_time,\n            is_tag,\n            is_ignore,\n        })\n    }\n}\n\npub fn expand_writeable(input: DeriveInput) -> syn::Result<TokenStream> {\n    let ident = input.ident;\n    let (impl_generics, ty_generics, where_clause) = input.generics.split_for_impl();\n\n    let fields = match input.data {\n        Data::Struct(strukt) => strukt.fields,\n        Data::Enum(inum) => {\n            return Err(syn::Error::new(\n                inum.enum_token.span,\n                \"#[derive(InfluxDbWriteable)] can only be used on structs\",\n            ))\n        }\n        Data::Union(cdu) => {\n            return Err(syn::Error::new(\n                cdu.union_token.span,\n                \"#[derive(InfluxDbWriteable)] can only be used on structs\",\n            ))\n        }\n    };\n\n    let writeable_fields: Vec<WriteableField> = match fields {\n        Fields::Named(fields) => fields\n            .named\n            .into_iter()\n            .map(WriteableField::try_from)\n            .collect::<syn::Result<Vec<_>>>()?,\n        _ => panic!(\"A struct without named fields is not supported!\"),\n    };\n\n    // Find the time field\n    let mut time_field = None;\n    let mut time_field_ty = None;\n    for wf in &writeable_fields {\n        if wf.is_time {\n            if time_field.is_some() {\n                panic!(\"multiple time fields found!\");\n            }\n            time_field = Some(wf.ident.clone());\n            time_field_ty = Some(wf.ty.clone());\n        }\n    }\n\n    // There must be exactly one time field\n    let time_field = time_field.expect(\"no time field found\");\n    let time_field_ty = time_field_ty.unwrap();\n\n    // Generate field assignments (excluding time and ignored fields)\n    let field_assignments = writeable_fields\n        .into_iter()\n        .filter_map(|wf| {\n            if wf.is_ignore || wf.is_time {\n                None\n            } else {\n                let ident = wf.ident;\n                Some(match wf.is_tag {\n                    true => quote!(query.add_tag(stringify!(#ident), self.#ident)),\n                    false => quote!(query.add_field(stringify!(#ident), self.#ident)),\n                })\n            }\n        })\n        .collect::<Vec<_>>();\n\n    // Add a necessary where clause\n    let mut where_clause = where_clause.cloned().unwrap_or(WhereClause {\n        where_token: Default::default(),\n        predicates: Punctuated::new(),\n    });\n    let mut err_ty = type_path!(<::influxdb::Timestamp as ::core::convert::TryFrom>::Error);\n    err_ty\n        .path\n        .segments\n        .iter_mut()\n        .nth(err_ty.qself.as_ref().unwrap().position - 1)\n        .unwrap()\n        .arguments = PathArguments::AngleBracketed(AngleBracketedGenericArguments {\n        colon2_token: None,\n        lt_token: Default::default(),\n        args: [GenericArgument::Type(time_field_ty.clone())]\n            .into_iter()\n            .collect(),\n        gt_token: Default::default(),\n    });\n    where_clause\n        .predicates\n        .push(WherePredicate::Type(PredicateType {\n            lifetimes: None,\n            bounded_ty: Type::Path(err_ty),\n            colon_token: Default::default(),\n            bounds: [TypeParamBound::Lifetime(Lifetime {\n                apostrophe: Span::call_site(),\n                ident: format_ident!(\"static\"),\n            })]\n            .into_iter()\n            .collect(),\n        }));\n\n    // Assemble the rest of the code\n    Ok(quote! {\n        const _: () = {\n            mod __influxdb_private {\n                use ::influxdb::{InfluxDbWriteable, Timestamp};\n                use ::core::fmt::{self, Debug, Display, Formatter, Write as _};\n\n                pub enum Error<T>\n                where\n                    Timestamp: TryFrom<T>\n                {\n                    TimestampError(<Timestamp as TryFrom<T>>::Error),\n                    QueryError(<Timestamp as InfluxDbWriteable>::Error)\n                }\n\n                impl<T> Clone for Error<T>\n                where\n                    Timestamp: TryFrom<T>,\n                    <Timestamp as TryFrom<T>>::Error: Clone\n                {\n                    fn clone(&self) -> Self {\n                        match self {\n                            Self::TimestampError(err) => Self::TimestampError(err.clone()),\n                            Self::QueryError(err) => Self::QueryError(err.clone())\n                        }\n                    }\n                }\n\n                impl<T> Debug for Error<T>\n                where\n                    Timestamp: TryFrom<T>,\n                    <Timestamp as TryFrom<T>>::Error: Debug\n                {\n                    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n                        match self {\n                            Self::TimestampError(err) => f.debug_tuple(\"TimestampError\")\n                                .field(err)\n                                .finish(),\n                            Self::QueryError(err) => f.debug_tuple(\"QueryError\")\n                                .field(err)\n                                .finish()\n                        }\n                    }\n                }\n\n                impl<T> Display for Error<T>\n                where\n                    Timestamp: TryFrom<T>,\n                    <Timestamp as TryFrom<T>>::Error: Display\n                {\n                    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n                        match self {\n                            Self::TimestampError(err) => {\n                                write!(f, \"Unable to convert value to timestamp: {err}\")\n                            },\n                            Self::QueryError(err) => {\n                                write!(f, \"Unable to convert timestamp to query: {err}\")\n                            }\n                        }\n                    }\n                }\n\n                impl<T> ::std::error::Error for Error<T>\n                where\n                    Timestamp: TryFrom<T>,\n                    <Timestamp as TryFrom<T>>::Error: ::std::error::Error + 'static\n                {\n                    fn source(&self) -> Option<&(dyn ::std::error::Error + 'static)> {\n                        match self {\n                            Self::TimestampError(err) => Some(err),\n                            Self::QueryError(err) => Some(err)\n                        }\n                    }\n                }\n            }\n\n            impl #impl_generics ::influxdb::InfluxDbWriteable for #ident #ty_generics #where_clause {\n                type Error = __influxdb_private::Error<#time_field_ty>;\n\n                fn try_into_query<I: Into<String>>(\n                    self,\n                    name: I\n                ) -> ::core::result::Result<::influxdb::WriteQuery, Self::Error> {\n                    let timestamp: ::influxdb::Timestamp = self.#time_field\n                        .try_into()\n                        .map_err(__influxdb_private::Error::TimestampError)?;\n                    let mut query = timestamp.try_into_query(name)\n                        .map_err(__influxdb_private::Error::QueryError)?;\n                    #(\n                        query = #field_assignments;\n                    )*\n                    Ok(query)\n                }\n            }\n        };\n    })\n}\n","traces":[{"line":37,"address":[1001578,1001607,1000624],"length":1,"stats":{"Line":0}},{"line":38,"address":[1000654],"length":1,"stats":{"Line":0}},{"line":39,"address":[1001532,1000750,1000694],"length":1,"stats":{"Line":0}},{"line":40,"address":[1001573,1000785,1001396],"length":1,"stats":{"Line":0}},{"line":41,"address":[1000799,1001373,1000761],"length":1,"stats":{"Line":0}},{"line":42,"address":[1001228,1001378,1000834],"length":1,"stats":{"Line":0}},{"line":43,"address":[1000810,1000848,1001181],"length":1,"stats":{"Line":0}},{"line":44,"address":[1001036,1001186,1000954],"length":1,"stats":{"Line":0}},{"line":46,"address":[1000854,1000966],"length":1,"stats":{"Line":0}},{"line":54,"address":[1001616],"length":1,"stats":{"Line":0}},{"line":55,"address":[1001641],"length":1,"stats":{"Line":0}},{"line":62,"address":[966917,967299,964896],"length":1,"stats":{"Line":0}},{"line":63,"address":[964918],"length":1,"stats":{"Line":0}},{"line":64,"address":[965067],"length":1,"stats":{"Line":0}},{"line":65,"address":[965102],"length":1,"stats":{"Line":0}},{"line":66,"address":[965110],"length":1,"stats":{"Line":0}},{"line":67,"address":[965118],"length":1,"stats":{"Line":0}},{"line":69,"address":[965235,965126,965366,967219],"length":1,"stats":{"Line":0}},{"line":70,"address":[965428],"length":1,"stats":{"Line":0}},{"line":71,"address":[966188,966033],"length":1,"stats":{"Line":0}},{"line":72,"address":[966413,966298,966741],"length":1,"stats":{"Line":0}},{"line":73,"address":[966821],"length":1,"stats":{"Line":0}},{"line":74,"address":[966878],"length":1,"stats":{"Line":0}},{"line":75,"address":[966891],"length":1,"stats":{"Line":0}},{"line":76,"address":[966904],"length":1,"stats":{"Line":0}},{"line":84,"address":[965490,965616],"length":1,"stats":{"Line":0}},{"line":85,"address":[965545],"length":1,"stats":{"Line":0}},{"line":86,"address":[965572,967328,967338],"length":1,"stats":{"Line":0}},{"line":87,"address":[965599],"length":1,"stats":{"Line":0}},{"line":96,"address":[965663,965622],"length":1,"stats":{"Line":0}},{"line":98,"address":[965836],"length":1,"stats":{"Line":0}},{"line":99,"address":[965738],"length":1,"stats":{"Line":0}},{"line":100,"address":[965777],"length":1,"stats":{"Line":0}},{"line":101,"address":[965803],"length":1,"stats":{"Line":0}},{"line":102,"address":[965814],"length":1,"stats":{"Line":0}},{"line":103,"address":[965825],"length":1,"stats":{"Line":0}},{"line":108,"address":[968224,993374],"length":1,"stats":{"Line":0}},{"line":109,"address":[968285],"length":1,"stats":{"Line":0}},{"line":110,"address":[968486,968411],"length":1,"stats":{"Line":0}},{"line":112,"address":[968542],"length":1,"stats":{"Line":0}},{"line":113,"address":[968608],"length":1,"stats":{"Line":0}},{"line":114,"address":[968688],"length":1,"stats":{"Line":0}},{"line":115,"address":[968739,994301],"length":1,"stats":{"Line":0}},{"line":116,"address":[968732],"length":1,"stats":{"Line":0}},{"line":120,"address":[968781],"length":1,"stats":{"Line":0}},{"line":121,"address":[994412,968844],"length":1,"stats":{"Line":0}},{"line":122,"address":[968837],"length":1,"stats":{"Line":0}},{"line":128,"address":[968660],"length":1,"stats":{"Line":0}},{"line":129,"address":[969118,968878,969179],"length":1,"stats":{"Line":0}},{"line":132,"address":[969072],"length":1,"stats":{"Line":0}},{"line":138,"address":[969280],"length":1,"stats":{"Line":0}},{"line":139,"address":[969296],"length":1,"stats":{"Line":0}},{"line":140,"address":[969404,969324],"length":1,"stats":{"Line":0}},{"line":141,"address":[969514,994021],"length":1,"stats":{"Line":0}},{"line":142,"address":[993596],"length":1,"stats":{"Line":0}},{"line":145,"address":[993676,993625],"length":1,"stats":{"Line":0}},{"line":146,"address":[993858],"length":1,"stats":{"Line":0}},{"line":151,"address":[969529],"length":1,"stats":{"Line":0}},{"line":152,"address":[969611],"length":1,"stats":{"Line":0}},{"line":155,"address":[969731],"length":1,"stats":{"Line":0}},{"line":157,"address":[995717,994864,969851,996333],"length":1,"stats":{"Line":0}},{"line":158,"address":[994893,994949],"length":1,"stats":{"Line":0}},{"line":159,"address":[994936],"length":1,"stats":{"Line":0}},{"line":161,"address":[994958],"length":1,"stats":{"Line":0}},{"line":162,"address":[995002,995681],"length":1,"stats":{"Line":0}},{"line":163,"address":[995030,995723],"length":1,"stats":{"Line":0}},{"line":164,"address":[995011,995090],"length":1,"stats":{"Line":0}},{"line":171,"address":[969897,970031,969941],"length":1,"stats":{"Line":0}},{"line":172,"address":[969949],"length":1,"stats":{"Line":0}},{"line":173,"address":[970005],"length":1,"stats":{"Line":0}},{"line":175,"address":[970117,970182],"length":1,"stats":{"Line":0}},{"line":176,"address":[973354,973566],"length":1,"stats":{"Line":0}},{"line":179,"address":[973259],"length":1,"stats":{"Line":0}},{"line":180,"address":[973442,973370],"length":1,"stats":{"Line":0}},{"line":181,"address":[973538],"length":1,"stats":{"Line":0}},{"line":182,"address":[973079],"length":1,"stats":{"Line":0}},{"line":183,"address":[972729],"length":1,"stats":{"Line":0}},{"line":184,"address":[972740,972806],"length":1,"stats":{"Line":0}},{"line":185,"address":[972827],"length":1,"stats":{"Line":0}},{"line":186,"address":[972959],"length":1,"stats":{"Line":0}},{"line":187,"address":[972982],"length":1,"stats":{"Line":0}},{"line":188,"address":[972989,973058],"length":1,"stats":{"Line":0}},{"line":192,"address":[974462],"length":1,"stats":{"Line":0}},{"line":193,"address":[973732],"length":1,"stats":{"Line":0}},{"line":194,"address":[973740],"length":1,"stats":{"Line":0}},{"line":195,"address":[973920,973983],"length":1,"stats":{"Line":0}},{"line":196,"address":[974199],"length":1,"stats":{"Line":0}},{"line":197,"address":[974004],"length":1,"stats":{"Line":0}},{"line":198,"address":[974019,974174],"length":1,"stats":{"Line":0}},{"line":200,"address":[974432],"length":1,"stats":{"Line":0}},{"line":201,"address":[974455],"length":1,"stats":{"Line":0}},{"line":205,"address":[974709,993393],"length":1,"stats":{"Line":0}}],"covered":0,"coverable":92}],"coverage":59.80769230769231,"covered":311,"coverable":520}